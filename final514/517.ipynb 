{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "lVquczr_nz7_",
    "outputId": "72c28db7-880c-4b34-93fa-ae5d7f2fbee5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime as dt\n",
    "\n",
    "\n",
    "#----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "zdepvs6UomHR",
    "outputId": "250a56db-9f13-47f1-8a40-f45ab039d4c3"
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------------\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#----------------------------------------------------\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "#----------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "colab_type": "code",
    "id": "83rKmQojpBJU",
    "outputId": "f9cb282b-cbaf-4b10-b7e5-c28b8a9384e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "colab_type": "code",
    "id": "hx9fb7sTpNCE",
    "outputId": "306fa50f-de8e-48d0-fc71-61fa9be3fd7c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   fractal_dimension_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  diagnosis  \n",
       "0          0.4601                  0.11890          M  \n",
       "1          0.2750                  0.08902          M  \n",
       "2          0.3613                  0.08758          M  \n",
       "3          0.6638                  0.17300          M  \n",
       "4          0.2364                  0.07678          M  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Brest Cancer Dataset.csv')\n",
    "df.shape\n",
    "\n",
    "\n",
    "df.drop(['id'], axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "id": "X5jwStGIsukX",
    "outputId": "6dda5974-8aef-4f64-d24b-81746ba69d9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "colab_type": "code",
    "id": "3l2IUlrjs7n-",
    "outputId": "86a09c52-ec77-4d16-b8dd-fa91f8611d89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#maping M to 0 and B to 0\n",
    "df['diagnosis'] = df['diagnosis'].map({'M': 0, 'B': 1})\n",
    "df['diagnosis'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "colab_type": "code",
    "id": "unjrl3U_rMls",
    "outputId": "58288e38-97a3-422d-a30e-8326b6bea25c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8162c5cc487a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#                                                    random_state = 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KFold' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#train_test_split(X, Y, test_size = 0.1,random_state = 0\n",
    "\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X,\n",
    "#                                                    test_size = 0.1,\n",
    "#                                                    random_state = 0)\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "KFold(n_splits=10, shuffle=False, random_state=None)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "     X_train, X_test = X[train_index], X[test_index]\n",
    "     Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jc4kiZaYuyYV"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1DdqU07Ku5AB"
   },
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "colab_type": "code",
    "id": "eTntgWpiu9Ix",
    "outputId": "94e848c7-06de-4a8f-f918-6ec4fe0643a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to complete random search:  0:00:00.002918\n",
      "Accuracy Score: 0.9642857142857143\n",
      "Precision Score: 0.9767441860465116\n",
      "Recall Score: 0.9767441860465116\n",
      "F1 Score: 0.9767441860465116\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        13\n",
      "           1       0.98      0.98      0.98        43\n",
      "\n",
      "    accuracy                           0.96        56\n",
      "   macro avg       0.95      0.95      0.95        56\n",
      "weighted avg       0.96      0.96      0.96        56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "st=dt.now()\n",
    "knn = KNeighborsClassifier(n_neighbors =5)\n",
    "knn.fit(X_train, Y_train)\n",
    "print(\"Time taken to complete random search: \",dt.now()-st)\n",
    "\n",
    "\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "#Model Evaluation\n",
    "kacc = accuracy_score(Y_test, knn_pred)\n",
    "print('Accuracy Score: ' + str(kacc))\n",
    "\n",
    "print('Precision Score: ' + str(precision_score(Y_test, knn_pred)))\n",
    "\n",
    "print('Recall Score: ' + str(recall_score(Y_test, knn_pred)))\n",
    "\n",
    "print('F1 Score: ' + str(f1_score(Y_test, knn_pred)))\n",
    "\n",
    "print('Classification Report: \\n' + str(classification_report(Y_test, knn_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qb10b-QkvAH6"
   },
   "source": [
    "## Polynomial Support Vector Machine Classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "colab_type": "code",
    "id": "ekjLnmoVvBqF",
    "outputId": "f6c2de51-9ddd-4337-a199-daa67dbc5871"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to complete random search:  0:00:00.012906\n",
      "Accuracy Score: 0.9821428571428571\n",
      "Precision Score: 0.9772727272727273\n",
      "Recall Score: 1.0\n",
      "F1 Score: 0.9885057471264368\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        13\n",
      "           1       0.98      1.00      0.99        43\n",
      "\n",
      "    accuracy                           0.98        56\n",
      "   macro avg       0.99      0.96      0.97        56\n",
      "weighted avg       0.98      0.98      0.98        56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "st=dt.now()\n",
    "p_svc = SVC(kernel = 'poly')\n",
    "p_svc.fit(X_train, Y_train)\n",
    "print(\"Time taken to complete random search: \",dt.now()-st)\n",
    "\n",
    "p_pred = p_svc.predict(X_test)\n",
    "\n",
    "#Model Evaluation\n",
    "lsvcacc = accuracy_score(Y_test, p_pred)\n",
    "print('Accuracy Score: ' + str(lsvcacc))\n",
    "\n",
    "print('Precision Score: ' + str(precision_score(Y_test, l_pred)))\n",
    "\n",
    "print('Recall Score: ' + str(recall_score(Y_test, l_pred)))\n",
    "\n",
    "print('F1 Score: ' + str(f1_score(Y_test, l_pred)))\n",
    "\n",
    "print('Classification Report: \\n' + str(classification_report(Y_test, l_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "colab_type": "code",
    "id": "RYhFtCxRvHeG",
    "outputId": "603dbb68-3868-49ea-8ac4-222ba8f01136"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to complete random search:  0:00:00.017108\n",
      "Accuracy Score: 0.9821428571428571\n",
      "Precision Score: 0.9772727272727273\n",
      "Recall Score: 1.0\n",
      "F1 Score: 0.9885057471264368\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        13\n",
      "           1       0.98      1.00      0.99        43\n",
      "\n",
      "    accuracy                           0.98        56\n",
      "   macro avg       0.99      0.96      0.97        56\n",
      "weighted avg       0.98      0.98      0.98        56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "st=dt.now()\n",
    "gk_svc = SVC(kernel = 'rbf')\n",
    "gk_svc.fit(X_train, Y_train)\n",
    "print(\"Time taken to complete random search: \",dt.now()-st)\n",
    "\n",
    "gk_pred = gk_svc.predict(X_test)\n",
    "\n",
    "#Model Evaluation\n",
    "ksvcaccacc = accuracy_score(Y_test, gk_pred)\n",
    "print('Accuracy Score: ' + str(ksvcaccacc))\n",
    "\n",
    "print('Precision Score: ' + str(precision_score(Y_test, gk_pred)))\n",
    "\n",
    "print('Recall Score: ' + str(recall_score(Y_test, gk_pred)))\n",
    "\n",
    "print('F1 Score: ' + str(f1_score(Y_test, gk_pred)))\n",
    "\n",
    "print('Classification Report: \\n' + str(classification_report(Y_test, gk_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eVrSlVu3vJ_Q"
   },
   "source": [
    "## Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "colab_type": "code",
    "id": "K7tyPCf5vLGf",
    "outputId": "ab0d84be-b5b3-4368-d33d-7cbd9e0d9c28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to complete random search:  0:00:00.166743\n",
      "Accuracy Score: 1.0\n",
      "Precision Score: 1.0\n",
      "Recall Score: 1.0\n",
      "F1 Score: 1.0\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      1.00      1.00        43\n",
      "\n",
      "    accuracy                           1.00        56\n",
      "   macro avg       1.00      1.00      1.00        56\n",
      "weighted avg       1.00      1.00      1.00        56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "st=dt.now()\n",
    "randomforest = RandomForestClassifier(n_estimators = 100, \n",
    "                                      random_state = 0, criterion = 'gini')\n",
    "randomforest.fit(X_train, Y_train)\n",
    "print(\"Time taken to complete random search: \",dt.now()-st)\n",
    "\n",
    "random_pred = randomforest.predict(X_test)\n",
    "\n",
    "#Model Evaluation\n",
    "rmacc = accuracy_score(Y_test, random_pred)\n",
    "print('Accuracy Score: ' + str(rmacc))\n",
    "\n",
    "print('Precision Score: ' + str(precision_score(Y_test, random_pred)))\n",
    "\n",
    "print('Recall Score: ' + str(recall_score(Y_test, random_pred)))\n",
    "\n",
    "print('F1 Score: ' + str(f1_score(Y_test, random_pred)))\n",
    "\n",
    "print('Classification Report: \\n' + str(classification_report(Y_test, random_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "znuuHTFavN0y"
   },
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "colab_type": "code",
    "id": "63jo8qvwvPMR",
    "outputId": "c502966d-21af-458a-c53a-cb311ef8288f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to complete random search:  0:00:00.008578\n",
      "Accuracy Score: 0.9107142857142857\n",
      "Precision Score: 0.9523809523809523\n",
      "Recall Score: 0.9302325581395349\n",
      "F1 Score: 0.9411764705882352\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.81        13\n",
      "           1       0.95      0.93      0.94        43\n",
      "\n",
      "    accuracy                           0.91        56\n",
      "   macro avg       0.87      0.89      0.88        56\n",
      "weighted avg       0.91      0.91      0.91        56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "st=dt.now()\n",
    "decison = DecisionTreeClassifier(criterion = 'gini', \n",
    "                                 random_state = 0)\n",
    "decison.fit(X_train, Y_train)\n",
    "print(\"Time taken to complete random search: \",dt.now()-st)\n",
    "\n",
    "decison_pred = decison.predict(X_test)\n",
    "\n",
    "#Model Evaluation\n",
    "dtacc = accuracy_score(Y_test, decison_pred)\n",
    "print('Accuracy Score: ' + str(dtacc))\n",
    "\n",
    "print('Precision Score: ' + str(precision_score(Y_test, decison_pred)))\n",
    "\n",
    "print('Recall Score: ' + str(recall_score(Y_test, decison_pred)))\n",
    "\n",
    "print('F1 Score: ' + str(f1_score(Y_test, decison_pred)))\n",
    "\n",
    "print('Classification Report: \\n' + str(classification_report(Y_test, decison_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OxFB4X9Qvahr"
   },
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "colab_type": "code",
    "id": "5Jb6rBwavZK2",
    "outputId": "662e43bf-e743-4934-8f78-efc2659506a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_93 (Dense)             (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Building Our Model\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "#Input and 1st Hidden Layer\n",
    "classifier.add(Dense(units = 20,\n",
    "                     activation = 'relu',\n",
    "                     kernel_initializer = 'uniform',\n",
    "                     input_dim = 30))\n",
    "classifier.add(Dropout(p = 0.2))\n",
    "\n",
    "\n",
    "#2nd Hidden Layer\n",
    "classifier.add(Dense(units = 20,\n",
    "                     activation = 'relu',\n",
    "                     kernel_initializer = 'uniform'))\n",
    "classifier.add(Dropout(p = 0.2))   \n",
    "\n",
    "\n",
    "#3rd Hidden Layer\n",
    "classifier.add(Dense(units = 20,\n",
    "                     activation = 'relu',\n",
    "                     kernel_initializer = 'uniform'))\n",
    "classifier.add(Dropout(p = 0.2))               \n",
    "\n",
    "#Output Layer\n",
    "classifier.add(Dense(units = 1,\n",
    "                     activation = 'sigmoid',\n",
    "                     kernel_initializer = 'uniform'))\n",
    "\n",
    "classifier.compile(optimizer = 'SGD',\n",
    "                   loss = 'binary_crossentropy',\n",
    "                   metrics = ['accuracy']) \n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "GfHO3yJ0xzpW",
    "outputId": "2371d4c5-d4ae-4ff2-a96e-29824b57ffb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 461 samples, validate on 52 samples\n",
      "Epoch 1/500\n",
      "461/461 [==============================] - 1s 2ms/step - loss: 0.6924 - accuracy: 0.6247 - val_loss: 0.6862 - val_accuracy: 0.7692\n",
      "Epoch 2/500\n",
      "461/461 [==============================] - 0s 114us/step - loss: 0.6870 - accuracy: 0.6876 - val_loss: 0.6823 - val_accuracy: 0.8846\n",
      "Epoch 3/500\n",
      "461/461 [==============================] - 0s 112us/step - loss: 0.6819 - accuracy: 0.6659 - val_loss: 0.6803 - val_accuracy: 0.6923\n",
      "Epoch 4/500\n",
      "461/461 [==============================] - 0s 110us/step - loss: 0.6722 - accuracy: 0.5575 - val_loss: 0.6826 - val_accuracy: 0.3462\n",
      "Epoch 5/500\n",
      "461/461 [==============================] - 0s 113us/step - loss: 0.6628 - accuracy: 0.5879 - val_loss: 0.6915 - val_accuracy: 0.2692\n",
      "Epoch 6/500\n",
      "461/461 [==============================] - 0s 112us/step - loss: 0.6484 - accuracy: 0.5944 - val_loss: 0.6999 - val_accuracy: 0.2692\n",
      "Epoch 7/500\n",
      "461/461 [==============================] - 0s 111us/step - loss: 0.6335 - accuracy: 0.6009 - val_loss: 0.6594 - val_accuracy: 0.5769\n",
      "Epoch 8/500\n",
      "461/461 [==============================] - 0s 113us/step - loss: 0.6283 - accuracy: 0.6811 - val_loss: 0.6742 - val_accuracy: 0.3462\n",
      "Epoch 9/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.6245 - accuracy: 0.6638 - val_loss: 0.6362 - val_accuracy: 0.7308\n",
      "Epoch 10/500\n",
      "461/461 [==============================] - 0s 112us/step - loss: 0.6030 - accuracy: 0.7397 - val_loss: 0.6088 - val_accuracy: 0.8654\n",
      "Epoch 11/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.5850 - accuracy: 0.7614 - val_loss: 0.5729 - val_accuracy: 0.8846\n",
      "Epoch 12/500\n",
      "461/461 [==============================] - 0s 113us/step - loss: 0.5539 - accuracy: 0.7852 - val_loss: 0.5325 - val_accuracy: 0.9038\n",
      "Epoch 13/500\n",
      "461/461 [==============================] - 0s 111us/step - loss: 0.5596 - accuracy: 0.7787 - val_loss: 0.5417 - val_accuracy: 0.9038\n",
      "Epoch 14/500\n",
      "461/461 [==============================] - 0s 113us/step - loss: 0.5160 - accuracy: 0.8243 - val_loss: 0.5553 - val_accuracy: 0.7692\n",
      "Epoch 15/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.4850 - accuracy: 0.8178 - val_loss: 0.4825 - val_accuracy: 0.8846\n",
      "Epoch 16/500\n",
      "461/461 [==============================] - 0s 112us/step - loss: 0.5606 - accuracy: 0.7419 - val_loss: 0.5853 - val_accuracy: 0.7500\n",
      "Epoch 17/500\n",
      "461/461 [==============================] - 0s 118us/step - loss: 0.5023 - accuracy: 0.8004 - val_loss: 0.6345 - val_accuracy: 0.5769\n",
      "Epoch 18/500\n",
      "461/461 [==============================] - 0s 111us/step - loss: 0.5267 - accuracy: 0.7744 - val_loss: 0.4652 - val_accuracy: 0.9231\n",
      "Epoch 19/500\n",
      "461/461 [==============================] - 0s 110us/step - loss: 0.5052 - accuracy: 0.7918 - val_loss: 0.5053 - val_accuracy: 0.8269\n",
      "Epoch 20/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.5050 - accuracy: 0.7831 - val_loss: 0.4259 - val_accuracy: 0.9231\n",
      "Epoch 21/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.4626 - accuracy: 0.8069 - val_loss: 0.4340 - val_accuracy: 0.8654\n",
      "Epoch 22/500\n",
      "461/461 [==============================] - 0s 110us/step - loss: 0.4473 - accuracy: 0.8416 - val_loss: 0.4153 - val_accuracy: 0.8654\n",
      "Epoch 23/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.4528 - accuracy: 0.8308 - val_loss: 0.4840 - val_accuracy: 0.8462\n",
      "Epoch 24/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.4275 - accuracy: 0.8612 - val_loss: 0.5695 - val_accuracy: 0.7500\n",
      "Epoch 25/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.4417 - accuracy: 0.8351 - val_loss: 0.3875 - val_accuracy: 0.9231\n",
      "Epoch 26/500\n",
      "461/461 [==============================] - 0s 115us/step - loss: 0.4517 - accuracy: 0.8069 - val_loss: 0.4520 - val_accuracy: 0.8654\n",
      "Epoch 27/500\n",
      "461/461 [==============================] - 0s 118us/step - loss: 0.3999 - accuracy: 0.8655 - val_loss: 0.4099 - val_accuracy: 0.8654\n",
      "Epoch 28/500\n",
      "461/461 [==============================] - 0s 112us/step - loss: 0.4062 - accuracy: 0.8482 - val_loss: 0.4890 - val_accuracy: 0.8269\n",
      "Epoch 29/500\n",
      "461/461 [==============================] - 0s 108us/step - loss: 0.3974 - accuracy: 0.8416 - val_loss: 0.4198 - val_accuracy: 0.9038\n",
      "Epoch 30/500\n",
      "461/461 [==============================] - 0s 114us/step - loss: 0.4066 - accuracy: 0.8308 - val_loss: 0.5260 - val_accuracy: 0.7692\n",
      "Epoch 31/500\n",
      "461/461 [==============================] - 0s 109us/step - loss: 0.4189 - accuracy: 0.8482 - val_loss: 0.4172 - val_accuracy: 0.8654\n",
      "Epoch 32/500\n",
      "461/461 [==============================] - 0s 110us/step - loss: 0.4294 - accuracy: 0.8265 - val_loss: 0.4903 - val_accuracy: 0.8077\n",
      "Epoch 33/500\n",
      "461/461 [==============================] - 0s 117us/step - loss: 0.4306 - accuracy: 0.8265 - val_loss: 0.3888 - val_accuracy: 0.8846\n",
      "Epoch 34/500\n",
      "461/461 [==============================] - 0s 111us/step - loss: 0.3740 - accuracy: 0.8525 - val_loss: 0.3513 - val_accuracy: 0.9038\n",
      "Epoch 35/500\n",
      "461/461 [==============================] - 0s 111us/step - loss: 0.3875 - accuracy: 0.8590 - val_loss: 0.4597 - val_accuracy: 0.8269\n",
      "Epoch 36/500\n",
      "461/461 [==============================] - 0s 107us/step - loss: 0.3466 - accuracy: 0.8807 - val_loss: 0.4936 - val_accuracy: 0.7885\n",
      "Epoch 37/500\n",
      "461/461 [==============================] - 0s 112us/step - loss: 0.3625 - accuracy: 0.8850 - val_loss: 0.4622 - val_accuracy: 0.8462\n",
      "Epoch 38/500\n",
      "461/461 [==============================] - 0s 112us/step - loss: 0.3464 - accuracy: 0.8894 - val_loss: 0.4254 - val_accuracy: 0.8654\n",
      "Epoch 39/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.3356 - accuracy: 0.8937 - val_loss: 0.3877 - val_accuracy: 0.8654\n",
      "Epoch 40/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.4057 - accuracy: 0.8655 - val_loss: 0.4542 - val_accuracy: 0.8846\n",
      "Epoch 41/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.4089 - accuracy: 0.8633 - val_loss: 0.3529 - val_accuracy: 0.9038\n",
      "Epoch 42/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.3884 - accuracy: 0.8568 - val_loss: 0.3462 - val_accuracy: 0.8654\n",
      "Epoch 43/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.3391 - accuracy: 0.8915 - val_loss: 0.3499 - val_accuracy: 0.8654\n",
      "Epoch 44/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.3809 - accuracy: 0.8438 - val_loss: 0.6082 - val_accuracy: 0.6923\n",
      "Epoch 45/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.3653 - accuracy: 0.8503 - val_loss: 0.3257 - val_accuracy: 0.9038\n",
      "Epoch 46/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.3687 - accuracy: 0.8677 - val_loss: 0.4118 - val_accuracy: 0.8462\n",
      "Epoch 47/500\n",
      "461/461 [==============================] - 0s 109us/step - loss: 0.3486 - accuracy: 0.8742 - val_loss: 0.3824 - val_accuracy: 0.8654\n",
      "Epoch 48/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.3361 - accuracy: 0.8742 - val_loss: 0.3192 - val_accuracy: 0.8846\n",
      "Epoch 49/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.3797 - accuracy: 0.8503 - val_loss: 0.3325 - val_accuracy: 0.9038\n",
      "Epoch 50/500\n",
      "461/461 [==============================] - 0s 109us/step - loss: 0.3542 - accuracy: 0.8633 - val_loss: 0.3249 - val_accuracy: 0.9038\n",
      "Epoch 51/500\n",
      "461/461 [==============================] - 0s 107us/step - loss: 0.3341 - accuracy: 0.8698 - val_loss: 0.3620 - val_accuracy: 0.8846\n",
      "Epoch 52/500\n",
      "461/461 [==============================] - 0s 108us/step - loss: 0.3178 - accuracy: 0.8872 - val_loss: 0.4468 - val_accuracy: 0.8462\n",
      "Epoch 53/500\n",
      "461/461 [==============================] - 0s 110us/step - loss: 0.3434 - accuracy: 0.8807 - val_loss: 0.3779 - val_accuracy: 0.8654\n",
      "Epoch 54/500\n",
      "461/461 [==============================] - 0s 110us/step - loss: 0.2883 - accuracy: 0.9046 - val_loss: 0.3571 - val_accuracy: 0.8846\n",
      "Epoch 55/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.3199 - accuracy: 0.8959 - val_loss: 0.3587 - val_accuracy: 0.8846\n",
      "Epoch 56/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2964 - accuracy: 0.9067 - val_loss: 0.3040 - val_accuracy: 0.8654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.3419 - accuracy: 0.8764 - val_loss: 0.3296 - val_accuracy: 0.8654\n",
      "Epoch 58/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.3306 - accuracy: 0.8612 - val_loss: 0.2976 - val_accuracy: 0.9231\n",
      "Epoch 59/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.3094 - accuracy: 0.9002 - val_loss: 0.3446 - val_accuracy: 0.8846\n",
      "Epoch 60/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.3010 - accuracy: 0.8829 - val_loss: 0.3040 - val_accuracy: 0.8846\n",
      "Epoch 61/500\n",
      "461/461 [==============================] - 0s 108us/step - loss: 0.2913 - accuracy: 0.9002 - val_loss: 0.2988 - val_accuracy: 0.8654\n",
      "Epoch 62/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.3304 - accuracy: 0.8720 - val_loss: 0.2924 - val_accuracy: 0.9231\n",
      "Epoch 63/500\n",
      "461/461 [==============================] - 0s 107us/step - loss: 0.3002 - accuracy: 0.9024 - val_loss: 0.2853 - val_accuracy: 0.9231\n",
      "Epoch 64/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2726 - accuracy: 0.9111 - val_loss: 0.5262 - val_accuracy: 0.7692\n",
      "Epoch 65/500\n",
      "461/461 [==============================] - 0s 107us/step - loss: 0.3039 - accuracy: 0.8829 - val_loss: 0.5899 - val_accuracy: 0.7500\n",
      "Epoch 66/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.3352 - accuracy: 0.8633 - val_loss: 0.3472 - val_accuracy: 0.8846\n",
      "Epoch 67/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2989 - accuracy: 0.8894 - val_loss: 0.3975 - val_accuracy: 0.8462\n",
      "Epoch 68/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.3154 - accuracy: 0.8829 - val_loss: 0.3698 - val_accuracy: 0.8462\n",
      "Epoch 69/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2857 - accuracy: 0.8980 - val_loss: 0.4651 - val_accuracy: 0.8077\n",
      "Epoch 70/500\n",
      "461/461 [==============================] - 0s 100us/step - loss: 0.3008 - accuracy: 0.8807 - val_loss: 0.3822 - val_accuracy: 0.8462\n",
      "Epoch 71/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2958 - accuracy: 0.8915 - val_loss: 0.6153 - val_accuracy: 0.7692\n",
      "Epoch 72/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2980 - accuracy: 0.8937 - val_loss: 0.4541 - val_accuracy: 0.8462\n",
      "Epoch 73/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.3784 - accuracy: 0.8416 - val_loss: 0.2858 - val_accuracy: 0.9038\n",
      "Epoch 74/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2905 - accuracy: 0.8959 - val_loss: 0.5174 - val_accuracy: 0.7885\n",
      "Epoch 75/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2882 - accuracy: 0.8850 - val_loss: 0.2749 - val_accuracy: 0.9038\n",
      "Epoch 76/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2996 - accuracy: 0.8850 - val_loss: 0.3283 - val_accuracy: 0.8846\n",
      "Epoch 77/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2873 - accuracy: 0.9024 - val_loss: 0.3394 - val_accuracy: 0.8846\n",
      "Epoch 78/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2583 - accuracy: 0.9111 - val_loss: 0.5007 - val_accuracy: 0.7885\n",
      "Epoch 79/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2824 - accuracy: 0.8937 - val_loss: 0.3328 - val_accuracy: 0.8846\n",
      "Epoch 80/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2795 - accuracy: 0.9002 - val_loss: 0.3149 - val_accuracy: 0.8846\n",
      "Epoch 81/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2656 - accuracy: 0.9111 - val_loss: 0.2680 - val_accuracy: 0.9231\n",
      "Epoch 82/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2743 - accuracy: 0.8937 - val_loss: 0.2696 - val_accuracy: 0.8654\n",
      "Epoch 83/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2878 - accuracy: 0.9002 - val_loss: 0.5714 - val_accuracy: 0.7692\n",
      "Epoch 84/500\n",
      "461/461 [==============================] - 0s 108us/step - loss: 0.2619 - accuracy: 0.9024 - val_loss: 0.2676 - val_accuracy: 0.8846\n",
      "Epoch 85/500\n",
      "461/461 [==============================] - 0s 108us/step - loss: 0.2351 - accuracy: 0.9306 - val_loss: 0.2945 - val_accuracy: 0.8654\n",
      "Epoch 86/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2706 - accuracy: 0.9067 - val_loss: 0.3797 - val_accuracy: 0.8462\n",
      "Epoch 87/500\n",
      "461/461 [==============================] - 0s 108us/step - loss: 0.2881 - accuracy: 0.9002 - val_loss: 0.2611 - val_accuracy: 0.9038\n",
      "Epoch 88/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2696 - accuracy: 0.8980 - val_loss: 0.2608 - val_accuracy: 0.9231\n",
      "Epoch 89/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2824 - accuracy: 0.8937 - val_loss: 0.2575 - val_accuracy: 0.9231\n",
      "Epoch 90/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.3030 - accuracy: 0.8764 - val_loss: 0.2953 - val_accuracy: 0.8654\n",
      "Epoch 91/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2702 - accuracy: 0.8980 - val_loss: 0.2849 - val_accuracy: 0.9038\n",
      "Epoch 92/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2495 - accuracy: 0.9089 - val_loss: 0.2681 - val_accuracy: 0.8654\n",
      "Epoch 93/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2472 - accuracy: 0.9067 - val_loss: 0.3821 - val_accuracy: 0.8654\n",
      "Epoch 94/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2377 - accuracy: 0.9154 - val_loss: 0.3944 - val_accuracy: 0.8462\n",
      "Epoch 95/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2537 - accuracy: 0.9024 - val_loss: 0.2509 - val_accuracy: 0.9231\n",
      "Epoch 96/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2795 - accuracy: 0.8937 - val_loss: 0.2700 - val_accuracy: 0.8654\n",
      "Epoch 97/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2666 - accuracy: 0.8937 - val_loss: 0.6397 - val_accuracy: 0.7500\n",
      "Epoch 98/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2512 - accuracy: 0.9046 - val_loss: 0.2632 - val_accuracy: 0.8846\n",
      "Epoch 99/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2427 - accuracy: 0.9046 - val_loss: 0.5946 - val_accuracy: 0.7692\n",
      "Epoch 100/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2597 - accuracy: 0.8980 - val_loss: 0.2464 - val_accuracy: 0.9231\n",
      "Epoch 101/500\n",
      "461/461 [==============================] - 0s 107us/step - loss: 0.2735 - accuracy: 0.8937 - val_loss: 0.2488 - val_accuracy: 0.9231\n",
      "Epoch 102/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.2843 - accuracy: 0.8937 - val_loss: 0.3137 - val_accuracy: 0.8846\n",
      "Epoch 103/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2639 - accuracy: 0.9197 - val_loss: 0.3799 - val_accuracy: 0.8462\n",
      "Epoch 104/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2657 - accuracy: 0.9024 - val_loss: 0.2470 - val_accuracy: 0.9038\n",
      "Epoch 105/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2591 - accuracy: 0.8959 - val_loss: 0.2533 - val_accuracy: 0.8846\n",
      "Epoch 106/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2403 - accuracy: 0.9132 - val_loss: 0.2547 - val_accuracy: 0.9231\n",
      "Epoch 107/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2819 - accuracy: 0.8894 - val_loss: 0.3287 - val_accuracy: 0.8846\n",
      "Epoch 108/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2603 - accuracy: 0.9024 - val_loss: 0.2665 - val_accuracy: 0.8846\n",
      "Epoch 109/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2548 - accuracy: 0.9089 - val_loss: 0.3676 - val_accuracy: 0.8654\n",
      "Epoch 110/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2358 - accuracy: 0.9089 - val_loss: 0.2484 - val_accuracy: 0.9231\n",
      "Epoch 111/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2380 - accuracy: 0.9111 - val_loss: 0.2424 - val_accuracy: 0.9038\n",
      "Epoch 112/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2525 - accuracy: 0.9176 - val_loss: 0.3913 - val_accuracy: 0.8462\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461/461 [==============================] - 0s 104us/step - loss: 0.2737 - accuracy: 0.8850 - val_loss: 0.2609 - val_accuracy: 0.8846\n",
      "Epoch 114/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2584 - accuracy: 0.9024 - val_loss: 0.7350 - val_accuracy: 0.6731\n",
      "Epoch 115/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2668 - accuracy: 0.9002 - val_loss: 0.2456 - val_accuracy: 0.9231\n",
      "Epoch 116/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2724 - accuracy: 0.8807 - val_loss: 0.2728 - val_accuracy: 0.9038\n",
      "Epoch 117/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2467 - accuracy: 0.9089 - val_loss: 0.3256 - val_accuracy: 0.8654\n",
      "Epoch 118/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2503 - accuracy: 0.9002 - val_loss: 0.2346 - val_accuracy: 0.9038\n",
      "Epoch 119/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2460 - accuracy: 0.9024 - val_loss: 0.2431 - val_accuracy: 0.8846\n",
      "Epoch 120/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.2539 - accuracy: 0.8915 - val_loss: 0.3266 - val_accuracy: 0.8462\n",
      "Epoch 121/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2574 - accuracy: 0.9089 - val_loss: 0.2438 - val_accuracy: 0.9231\n",
      "Epoch 122/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2720 - accuracy: 0.8915 - val_loss: 0.2386 - val_accuracy: 0.9231\n",
      "Epoch 123/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2601 - accuracy: 0.8959 - val_loss: 0.2394 - val_accuracy: 0.8846\n",
      "Epoch 124/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2487 - accuracy: 0.9024 - val_loss: 0.2417 - val_accuracy: 0.9231\n",
      "Epoch 125/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2629 - accuracy: 0.8980 - val_loss: 0.3113 - val_accuracy: 0.8846\n",
      "Epoch 126/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2477 - accuracy: 0.9024 - val_loss: 0.2363 - val_accuracy: 0.8846\n",
      "Epoch 127/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2493 - accuracy: 0.9067 - val_loss: 0.2742 - val_accuracy: 0.8654\n",
      "Epoch 128/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2637 - accuracy: 0.8959 - val_loss: 0.2753 - val_accuracy: 0.8654\n",
      "Epoch 129/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2401 - accuracy: 0.9089 - val_loss: 0.2833 - val_accuracy: 0.8846\n",
      "Epoch 130/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2717 - accuracy: 0.8915 - val_loss: 0.2529 - val_accuracy: 0.8846\n",
      "Epoch 131/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2673 - accuracy: 0.9046 - val_loss: 0.3487 - val_accuracy: 0.8654\n",
      "Epoch 132/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2523 - accuracy: 0.9046 - val_loss: 0.2819 - val_accuracy: 0.8654\n",
      "Epoch 133/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2516 - accuracy: 0.9111 - val_loss: 0.2476 - val_accuracy: 0.8846\n",
      "Epoch 134/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2402 - accuracy: 0.9067 - val_loss: 0.2455 - val_accuracy: 0.8846\n",
      "Epoch 135/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2321 - accuracy: 0.9111 - val_loss: 0.2426 - val_accuracy: 0.9038\n",
      "Epoch 136/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2233 - accuracy: 0.9176 - val_loss: 0.2569 - val_accuracy: 0.8846\n",
      "Epoch 137/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2568 - accuracy: 0.8937 - val_loss: 0.4387 - val_accuracy: 0.8462\n",
      "Epoch 138/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2297 - accuracy: 0.9197 - val_loss: 0.2556 - val_accuracy: 0.8846\n",
      "Epoch 139/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2203 - accuracy: 0.9154 - val_loss: 0.2484 - val_accuracy: 0.8846\n",
      "Epoch 140/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2600 - accuracy: 0.8980 - val_loss: 0.3053 - val_accuracy: 0.8846\n",
      "Epoch 141/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2454 - accuracy: 0.9154 - val_loss: 0.2587 - val_accuracy: 0.8654\n",
      "Epoch 142/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2728 - accuracy: 0.8959 - val_loss: 0.4244 - val_accuracy: 0.8462\n",
      "Epoch 143/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2402 - accuracy: 0.9046 - val_loss: 0.4120 - val_accuracy: 0.8462\n",
      "Epoch 144/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2395 - accuracy: 0.8980 - val_loss: 0.2841 - val_accuracy: 0.8654\n",
      "Epoch 145/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2346 - accuracy: 0.9024 - val_loss: 0.4060 - val_accuracy: 0.8462\n",
      "Epoch 146/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2430 - accuracy: 0.9046 - val_loss: 0.2376 - val_accuracy: 0.8846\n",
      "Epoch 147/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2396 - accuracy: 0.9111 - val_loss: 0.3697 - val_accuracy: 0.8462\n",
      "Epoch 148/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2497 - accuracy: 0.9002 - val_loss: 0.3578 - val_accuracy: 0.8462\n",
      "Epoch 149/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2376 - accuracy: 0.9111 - val_loss: 0.2353 - val_accuracy: 0.8846\n",
      "Epoch 150/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2553 - accuracy: 0.9089 - val_loss: 0.6042 - val_accuracy: 0.7308\n",
      "Epoch 151/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2491 - accuracy: 0.8959 - val_loss: 0.4788 - val_accuracy: 0.7885\n",
      "Epoch 152/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2421 - accuracy: 0.9024 - val_loss: 0.4125 - val_accuracy: 0.8462\n",
      "Epoch 153/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2582 - accuracy: 0.9024 - val_loss: 0.8148 - val_accuracy: 0.6538\n",
      "Epoch 154/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2457 - accuracy: 0.8959 - val_loss: 0.2454 - val_accuracy: 0.8846\n",
      "Epoch 155/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2257 - accuracy: 0.9241 - val_loss: 0.3781 - val_accuracy: 0.8462\n",
      "Epoch 156/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2458 - accuracy: 0.9046 - val_loss: 0.2414 - val_accuracy: 0.9231\n",
      "Epoch 157/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2498 - accuracy: 0.8980 - val_loss: 0.3656 - val_accuracy: 0.8654\n",
      "Epoch 158/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.2373 - accuracy: 0.9154 - val_loss: 0.2907 - val_accuracy: 0.8846\n",
      "Epoch 159/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2264 - accuracy: 0.9002 - val_loss: 0.2818 - val_accuracy: 0.8846\n",
      "Epoch 160/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2394 - accuracy: 0.9067 - val_loss: 0.2351 - val_accuracy: 0.8846\n",
      "Epoch 161/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2514 - accuracy: 0.8980 - val_loss: 0.2772 - val_accuracy: 0.8654\n",
      "Epoch 162/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2592 - accuracy: 0.9111 - val_loss: 0.2616 - val_accuracy: 0.8846\n",
      "Epoch 163/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2601 - accuracy: 0.8915 - val_loss: 0.2226 - val_accuracy: 0.8846\n",
      "Epoch 164/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2327 - accuracy: 0.9046 - val_loss: 0.2771 - val_accuracy: 0.8846\n",
      "Epoch 165/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2415 - accuracy: 0.9002 - val_loss: 0.3439 - val_accuracy: 0.8462\n",
      "Epoch 166/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2214 - accuracy: 0.9219 - val_loss: 0.3426 - val_accuracy: 0.8654\n",
      "Epoch 167/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2433 - accuracy: 0.9132 - val_loss: 0.2322 - val_accuracy: 0.8846\n",
      "Epoch 168/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2622 - accuracy: 0.8959 - val_loss: 0.2588 - val_accuracy: 0.8654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2461 - accuracy: 0.9132 - val_loss: 0.2944 - val_accuracy: 0.8846\n",
      "Epoch 170/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2450 - accuracy: 0.8959 - val_loss: 0.3179 - val_accuracy: 0.8846\n",
      "Epoch 171/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2252 - accuracy: 0.9176 - val_loss: 0.2827 - val_accuracy: 0.8846\n",
      "Epoch 172/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2273 - accuracy: 0.9111 - val_loss: 0.3274 - val_accuracy: 0.8846\n",
      "Epoch 173/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2390 - accuracy: 0.9111 - val_loss: 0.2362 - val_accuracy: 0.9231\n",
      "Epoch 174/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2276 - accuracy: 0.9067 - val_loss: 0.2955 - val_accuracy: 0.8846\n",
      "Epoch 175/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2300 - accuracy: 0.9197 - val_loss: 0.3857 - val_accuracy: 0.8462\n",
      "Epoch 176/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2392 - accuracy: 0.9089 - val_loss: 0.2955 - val_accuracy: 0.8846\n",
      "Epoch 177/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2597 - accuracy: 0.9002 - val_loss: 0.2506 - val_accuracy: 0.8846\n",
      "Epoch 178/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2246 - accuracy: 0.8937 - val_loss: 0.4144 - val_accuracy: 0.8462\n",
      "Epoch 179/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2536 - accuracy: 0.9046 - val_loss: 0.2297 - val_accuracy: 0.8846\n",
      "Epoch 180/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2578 - accuracy: 0.9067 - val_loss: 0.2823 - val_accuracy: 0.8654\n",
      "Epoch 181/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2393 - accuracy: 0.9024 - val_loss: 0.3520 - val_accuracy: 0.8462\n",
      "Epoch 182/500\n",
      "461/461 [==============================] - 0s 114us/step - loss: 0.2434 - accuracy: 0.9067 - val_loss: 0.2370 - val_accuracy: 0.8846\n",
      "Epoch 183/500\n",
      "461/461 [==============================] - 0s 109us/step - loss: 0.2282 - accuracy: 0.9046 - val_loss: 0.2589 - val_accuracy: 0.8654\n",
      "Epoch 184/500\n",
      "461/461 [==============================] - 0s 114us/step - loss: 0.1980 - accuracy: 0.9197 - val_loss: 0.2839 - val_accuracy: 0.8846\n",
      "Epoch 185/500\n",
      "461/461 [==============================] - 0s 132us/step - loss: 0.2692 - accuracy: 0.8915 - val_loss: 0.2573 - val_accuracy: 0.8654\n",
      "Epoch 186/500\n",
      "461/461 [==============================] - 0s 108us/step - loss: 0.2026 - accuracy: 0.9197 - val_loss: 0.2393 - val_accuracy: 0.8846\n",
      "Epoch 187/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2358 - accuracy: 0.9111 - val_loss: 0.2470 - val_accuracy: 0.8654\n",
      "Epoch 188/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2244 - accuracy: 0.9002 - val_loss: 0.2221 - val_accuracy: 0.9038\n",
      "Epoch 189/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2224 - accuracy: 0.9111 - val_loss: 0.2346 - val_accuracy: 0.8846\n",
      "Epoch 190/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2515 - accuracy: 0.9132 - val_loss: 0.2726 - val_accuracy: 0.8654\n",
      "Epoch 191/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2445 - accuracy: 0.9132 - val_loss: 0.2261 - val_accuracy: 0.9038\n",
      "Epoch 192/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2078 - accuracy: 0.9132 - val_loss: 0.3158 - val_accuracy: 0.8846\n",
      "Epoch 193/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2225 - accuracy: 0.9089 - val_loss: 0.2399 - val_accuracy: 0.8846\n",
      "Epoch 194/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2248 - accuracy: 0.9154 - val_loss: 0.3415 - val_accuracy: 0.8846\n",
      "Epoch 195/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2280 - accuracy: 0.9197 - val_loss: 0.2244 - val_accuracy: 0.9038\n",
      "Epoch 196/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2638 - accuracy: 0.8894 - val_loss: 0.2369 - val_accuracy: 0.8846\n",
      "Epoch 197/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2332 - accuracy: 0.9154 - val_loss: 0.2346 - val_accuracy: 0.8846\n",
      "Epoch 198/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2536 - accuracy: 0.9002 - val_loss: 0.2705 - val_accuracy: 0.8654\n",
      "Epoch 199/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2310 - accuracy: 0.9067 - val_loss: 0.2456 - val_accuracy: 0.8654\n",
      "Epoch 200/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.2543 - accuracy: 0.9154 - val_loss: 0.3276 - val_accuracy: 0.8654\n",
      "Epoch 201/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2145 - accuracy: 0.9176 - val_loss: 0.2466 - val_accuracy: 0.8654\n",
      "Epoch 202/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.2168 - accuracy: 0.9132 - val_loss: 0.2225 - val_accuracy: 0.8846\n",
      "Epoch 203/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2164 - accuracy: 0.9241 - val_loss: 0.4280 - val_accuracy: 0.8462\n",
      "Epoch 204/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2312 - accuracy: 0.9046 - val_loss: 0.2401 - val_accuracy: 0.9231\n",
      "Epoch 205/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2256 - accuracy: 0.9241 - val_loss: 0.3728 - val_accuracy: 0.8462\n",
      "Epoch 206/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2041 - accuracy: 0.9176 - val_loss: 0.2528 - val_accuracy: 0.8654\n",
      "Epoch 207/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2137 - accuracy: 0.9176 - val_loss: 0.3277 - val_accuracy: 0.8846\n",
      "Epoch 208/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2305 - accuracy: 0.9067 - val_loss: 0.2617 - val_accuracy: 0.8654\n",
      "Epoch 209/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2265 - accuracy: 0.9132 - val_loss: 0.2541 - val_accuracy: 0.8654\n",
      "Epoch 210/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2151 - accuracy: 0.9154 - val_loss: 0.3472 - val_accuracy: 0.8654\n",
      "Epoch 211/500\n",
      "461/461 [==============================] - 0s 110us/step - loss: 0.2177 - accuracy: 0.9197 - val_loss: 0.3056 - val_accuracy: 0.8846\n",
      "Epoch 212/500\n",
      "461/461 [==============================] - 0s 128us/step - loss: 0.2215 - accuracy: 0.9154 - val_loss: 0.2272 - val_accuracy: 0.8654\n",
      "Epoch 213/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2548 - accuracy: 0.8937 - val_loss: 0.2682 - val_accuracy: 0.8846\n",
      "Epoch 214/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.2130 - accuracy: 0.9262 - val_loss: 0.2561 - val_accuracy: 0.8654\n",
      "Epoch 215/500\n",
      "461/461 [==============================] - 0s 115us/step - loss: 0.2351 - accuracy: 0.9154 - val_loss: 0.2310 - val_accuracy: 0.8846\n",
      "Epoch 216/500\n",
      "461/461 [==============================] - 0s 111us/step - loss: 0.2125 - accuracy: 0.9154 - val_loss: 0.3809 - val_accuracy: 0.8462\n",
      "Epoch 217/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2116 - accuracy: 0.9371 - val_loss: 0.2577 - val_accuracy: 0.8654\n",
      "Epoch 218/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2180 - accuracy: 0.9219 - val_loss: 0.2586 - val_accuracy: 0.8654\n",
      "Epoch 219/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2164 - accuracy: 0.9176 - val_loss: 0.2522 - val_accuracy: 0.8654\n",
      "Epoch 220/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2455 - accuracy: 0.9154 - val_loss: 0.3010 - val_accuracy: 0.8846\n",
      "Epoch 221/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.2386 - accuracy: 0.9089 - val_loss: 0.3975 - val_accuracy: 0.8462\n",
      "Epoch 222/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2512 - accuracy: 0.8937 - val_loss: 0.2600 - val_accuracy: 0.8654\n",
      "Epoch 223/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2610 - accuracy: 0.8980 - val_loss: 0.2364 - val_accuracy: 0.8654\n",
      "Epoch 224/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2333 - accuracy: 0.9024 - val_loss: 0.2240 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/500\n",
      "461/461 [==============================] - 0s 109us/step - loss: 0.2563 - accuracy: 0.8980 - val_loss: 0.2540 - val_accuracy: 0.8654\n",
      "Epoch 226/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2429 - accuracy: 0.9197 - val_loss: 0.3871 - val_accuracy: 0.8462\n",
      "Epoch 227/500\n",
      "461/461 [==============================] - 0s 107us/step - loss: 0.2365 - accuracy: 0.9089 - val_loss: 0.2213 - val_accuracy: 0.8846\n",
      "Epoch 228/500\n",
      "461/461 [==============================] - 0s 107us/step - loss: 0.2435 - accuracy: 0.9111 - val_loss: 0.2407 - val_accuracy: 0.8846\n",
      "Epoch 229/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2068 - accuracy: 0.9284 - val_loss: 0.3512 - val_accuracy: 0.8846\n",
      "Epoch 230/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2216 - accuracy: 0.9197 - val_loss: 0.2724 - val_accuracy: 0.8654\n",
      "Epoch 231/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2168 - accuracy: 0.9002 - val_loss: 0.2858 - val_accuracy: 0.8846\n",
      "Epoch 232/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2179 - accuracy: 0.9219 - val_loss: 0.3161 - val_accuracy: 0.8654\n",
      "Epoch 233/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2512 - accuracy: 0.8959 - val_loss: 0.2262 - val_accuracy: 0.9038\n",
      "Epoch 234/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2123 - accuracy: 0.9089 - val_loss: 0.2259 - val_accuracy: 0.8846\n",
      "Epoch 235/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.2249 - accuracy: 0.9132 - val_loss: 0.3071 - val_accuracy: 0.8846\n",
      "Epoch 236/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2119 - accuracy: 0.9067 - val_loss: 0.2235 - val_accuracy: 0.8846\n",
      "Epoch 237/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2299 - accuracy: 0.9197 - val_loss: 0.2218 - val_accuracy: 0.9038\n",
      "Epoch 238/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2312 - accuracy: 0.8980 - val_loss: 0.3168 - val_accuracy: 0.8654\n",
      "Epoch 239/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2060 - accuracy: 0.9111 - val_loss: 0.2697 - val_accuracy: 0.8846\n",
      "Epoch 240/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2189 - accuracy: 0.9176 - val_loss: 0.2383 - val_accuracy: 0.8846\n",
      "Epoch 241/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2335 - accuracy: 0.8959 - val_loss: 0.4557 - val_accuracy: 0.8462\n",
      "Epoch 242/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2352 - accuracy: 0.9067 - val_loss: 0.2233 - val_accuracy: 0.8846\n",
      "Epoch 243/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2406 - accuracy: 0.9067 - val_loss: 0.2262 - val_accuracy: 0.8846\n",
      "Epoch 244/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.2176 - accuracy: 0.9197 - val_loss: 0.2970 - val_accuracy: 0.8846\n",
      "Epoch 245/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2079 - accuracy: 0.9111 - val_loss: 0.2278 - val_accuracy: 0.8846\n",
      "Epoch 246/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.2235 - accuracy: 0.9197 - val_loss: 0.2209 - val_accuracy: 0.9038\n",
      "Epoch 247/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2177 - accuracy: 0.9176 - val_loss: 0.2549 - val_accuracy: 0.8846\n",
      "Epoch 248/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2440 - accuracy: 0.9089 - val_loss: 0.3025 - val_accuracy: 0.8654\n",
      "Epoch 249/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2219 - accuracy: 0.9089 - val_loss: 0.2221 - val_accuracy: 0.8846\n",
      "Epoch 250/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1985 - accuracy: 0.9219 - val_loss: 0.6683 - val_accuracy: 0.7692\n",
      "Epoch 251/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2486 - accuracy: 0.9002 - val_loss: 0.2364 - val_accuracy: 0.8654\n",
      "Epoch 252/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2222 - accuracy: 0.9132 - val_loss: 0.2188 - val_accuracy: 0.9231\n",
      "Epoch 253/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2249 - accuracy: 0.9067 - val_loss: 0.2140 - val_accuracy: 0.9231\n",
      "Epoch 254/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2200 - accuracy: 0.9219 - val_loss: 0.2169 - val_accuracy: 0.9231\n",
      "Epoch 255/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2272 - accuracy: 0.9132 - val_loss: 0.2537 - val_accuracy: 0.8846\n",
      "Epoch 256/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2545 - accuracy: 0.9024 - val_loss: 0.2270 - val_accuracy: 0.9038\n",
      "Epoch 257/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2237 - accuracy: 0.9154 - val_loss: 0.2421 - val_accuracy: 0.8846\n",
      "Epoch 258/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2103 - accuracy: 0.9219 - val_loss: 0.2111 - val_accuracy: 0.9038\n",
      "Epoch 259/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2357 - accuracy: 0.9154 - val_loss: 0.2962 - val_accuracy: 0.8654\n",
      "Epoch 260/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2132 - accuracy: 0.9241 - val_loss: 0.2649 - val_accuracy: 0.8846\n",
      "Epoch 261/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2171 - accuracy: 0.9089 - val_loss: 0.4504 - val_accuracy: 0.8462\n",
      "Epoch 262/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2231 - accuracy: 0.9176 - val_loss: 0.2354 - val_accuracy: 0.8846\n",
      "Epoch 263/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2099 - accuracy: 0.9089 - val_loss: 0.2336 - val_accuracy: 0.8846\n",
      "Epoch 264/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2463 - accuracy: 0.9067 - val_loss: 0.2209 - val_accuracy: 0.9038\n",
      "Epoch 265/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2413 - accuracy: 0.9111 - val_loss: 0.2612 - val_accuracy: 0.8654\n",
      "Epoch 266/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2377 - accuracy: 0.9089 - val_loss: 0.2281 - val_accuracy: 0.8846\n",
      "Epoch 267/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2279 - accuracy: 0.9154 - val_loss: 0.2234 - val_accuracy: 0.9038\n",
      "Epoch 268/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2241 - accuracy: 0.9067 - val_loss: 0.2709 - val_accuracy: 0.8654\n",
      "Epoch 269/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2201 - accuracy: 0.9219 - val_loss: 0.2307 - val_accuracy: 0.8846\n",
      "Epoch 270/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2281 - accuracy: 0.9089 - val_loss: 0.2823 - val_accuracy: 0.8846\n",
      "Epoch 271/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2202 - accuracy: 0.9067 - val_loss: 0.2254 - val_accuracy: 0.9038\n",
      "Epoch 272/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2152 - accuracy: 0.9241 - val_loss: 0.2453 - val_accuracy: 0.8654\n",
      "Epoch 273/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2024 - accuracy: 0.9262 - val_loss: 0.2286 - val_accuracy: 0.9231\n",
      "Epoch 274/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2053 - accuracy: 0.9262 - val_loss: 0.3311 - val_accuracy: 0.8846\n",
      "Epoch 275/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2077 - accuracy: 0.9219 - val_loss: 0.3103 - val_accuracy: 0.8846\n",
      "Epoch 276/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2351 - accuracy: 0.9046 - val_loss: 0.2523 - val_accuracy: 0.8654\n",
      "Epoch 277/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1962 - accuracy: 0.9176 - val_loss: 0.2205 - val_accuracy: 0.8846\n",
      "Epoch 278/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2306 - accuracy: 0.9002 - val_loss: 0.2170 - val_accuracy: 0.9231\n",
      "Epoch 279/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2162 - accuracy: 0.9241 - val_loss: 0.2787 - val_accuracy: 0.8846\n",
      "Epoch 280/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2071 - accuracy: 0.9176 - val_loss: 0.2962 - val_accuracy: 0.8654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.2224 - accuracy: 0.9349 - val_loss: 0.2362 - val_accuracy: 0.9231\n",
      "Epoch 282/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2169 - accuracy: 0.9111 - val_loss: 0.2761 - val_accuracy: 0.8654\n",
      "Epoch 283/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.2230 - accuracy: 0.9132 - val_loss: 0.2524 - val_accuracy: 0.8846\n",
      "Epoch 284/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2175 - accuracy: 0.9154 - val_loss: 0.2258 - val_accuracy: 0.9038\n",
      "Epoch 285/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2229 - accuracy: 0.9089 - val_loss: 0.2522 - val_accuracy: 0.8654\n",
      "Epoch 286/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2187 - accuracy: 0.9132 - val_loss: 0.2620 - val_accuracy: 0.8846\n",
      "Epoch 287/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2351 - accuracy: 0.9132 - val_loss: 0.2254 - val_accuracy: 0.9038\n",
      "Epoch 288/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2063 - accuracy: 0.9197 - val_loss: 0.2164 - val_accuracy: 0.9038\n",
      "Epoch 289/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2245 - accuracy: 0.9067 - val_loss: 0.2308 - val_accuracy: 0.9038\n",
      "Epoch 290/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2242 - accuracy: 0.9132 - val_loss: 0.2631 - val_accuracy: 0.8846\n",
      "Epoch 291/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2132 - accuracy: 0.9132 - val_loss: 0.2206 - val_accuracy: 0.8846\n",
      "Epoch 292/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2112 - accuracy: 0.9262 - val_loss: 0.2254 - val_accuracy: 0.9038\n",
      "Epoch 293/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2129 - accuracy: 0.9176 - val_loss: 0.3606 - val_accuracy: 0.8462\n",
      "Epoch 294/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2363 - accuracy: 0.9046 - val_loss: 0.2481 - val_accuracy: 0.8846\n",
      "Epoch 295/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1999 - accuracy: 0.9176 - val_loss: 0.2320 - val_accuracy: 0.8846\n",
      "Epoch 296/500\n",
      "461/461 [==============================] - 0s 107us/step - loss: 0.2188 - accuracy: 0.9067 - val_loss: 0.3099 - val_accuracy: 0.8654\n",
      "Epoch 297/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2181 - accuracy: 0.9111 - val_loss: 0.2804 - val_accuracy: 0.8846\n",
      "Epoch 298/500\n",
      "461/461 [==============================] - 0s 108us/step - loss: 0.2138 - accuracy: 0.9241 - val_loss: 0.2211 - val_accuracy: 0.8846\n",
      "Epoch 299/500\n",
      "461/461 [==============================] - 0s 108us/step - loss: 0.1976 - accuracy: 0.9306 - val_loss: 0.2182 - val_accuracy: 0.8846\n",
      "Epoch 300/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.2040 - accuracy: 0.9197 - val_loss: 0.2167 - val_accuracy: 0.8846\n",
      "Epoch 301/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2243 - accuracy: 0.9197 - val_loss: 0.2462 - val_accuracy: 0.8846\n",
      "Epoch 302/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.2042 - accuracy: 0.9176 - val_loss: 0.2447 - val_accuracy: 0.8654\n",
      "Epoch 303/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.2180 - accuracy: 0.9176 - val_loss: 0.2222 - val_accuracy: 0.9231\n",
      "Epoch 304/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2168 - accuracy: 0.9111 - val_loss: 0.2947 - val_accuracy: 0.8846\n",
      "Epoch 305/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2209 - accuracy: 0.9176 - val_loss: 0.3768 - val_accuracy: 0.8462\n",
      "Epoch 306/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.1988 - accuracy: 0.9176 - val_loss: 0.2796 - val_accuracy: 0.8846\n",
      "Epoch 307/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2012 - accuracy: 0.9284 - val_loss: 0.2505 - val_accuracy: 0.8654\n",
      "Epoch 308/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2044 - accuracy: 0.9219 - val_loss: 0.2159 - val_accuracy: 0.9038\n",
      "Epoch 309/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2386 - accuracy: 0.9046 - val_loss: 0.3397 - val_accuracy: 0.8654\n",
      "Epoch 310/500\n",
      "461/461 [==============================] - 0s 108us/step - loss: 0.2183 - accuracy: 0.9197 - val_loss: 0.2132 - val_accuracy: 0.9038\n",
      "Epoch 311/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2243 - accuracy: 0.9067 - val_loss: 0.2488 - val_accuracy: 0.8654\n",
      "Epoch 312/500\n",
      "461/461 [==============================] - 0s 107us/step - loss: 0.2075 - accuracy: 0.9067 - val_loss: 0.2666 - val_accuracy: 0.8846\n",
      "Epoch 313/500\n",
      "461/461 [==============================] - 0s 109us/step - loss: 0.2005 - accuracy: 0.9176 - val_loss: 0.2104 - val_accuracy: 0.9038\n",
      "Epoch 314/500\n",
      "461/461 [==============================] - 0s 108us/step - loss: 0.2229 - accuracy: 0.9067 - val_loss: 0.3578 - val_accuracy: 0.8462\n",
      "Epoch 315/500\n",
      "461/461 [==============================] - 0s 108us/step - loss: 0.1891 - accuracy: 0.9262 - val_loss: 0.2641 - val_accuracy: 0.9231\n",
      "Epoch 316/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2328 - accuracy: 0.9154 - val_loss: 0.2182 - val_accuracy: 0.8846\n",
      "Epoch 317/500\n",
      "461/461 [==============================] - 0s 109us/step - loss: 0.2310 - accuracy: 0.9176 - val_loss: 0.2368 - val_accuracy: 0.8846\n",
      "Epoch 318/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2295 - accuracy: 0.8980 - val_loss: 0.2331 - val_accuracy: 0.8846\n",
      "Epoch 319/500\n",
      "461/461 [==============================] - 0s 108us/step - loss: 0.2030 - accuracy: 0.9089 - val_loss: 0.2126 - val_accuracy: 0.9038\n",
      "Epoch 320/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2046 - accuracy: 0.9219 - val_loss: 0.2175 - val_accuracy: 0.8846\n",
      "Epoch 321/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2040 - accuracy: 0.9262 - val_loss: 0.2207 - val_accuracy: 0.9038\n",
      "Epoch 322/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2192 - accuracy: 0.9046 - val_loss: 0.2249 - val_accuracy: 0.8846\n",
      "Epoch 323/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2111 - accuracy: 0.9176 - val_loss: 0.2512 - val_accuracy: 0.8654\n",
      "Epoch 324/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2072 - accuracy: 0.9197 - val_loss: 0.2276 - val_accuracy: 0.8846\n",
      "Epoch 325/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2164 - accuracy: 0.9132 - val_loss: 0.2191 - val_accuracy: 0.9038\n",
      "Epoch 326/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2091 - accuracy: 0.9284 - val_loss: 0.2375 - val_accuracy: 0.8846\n",
      "Epoch 327/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2192 - accuracy: 0.9067 - val_loss: 0.2205 - val_accuracy: 0.8846\n",
      "Epoch 328/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2011 - accuracy: 0.9197 - val_loss: 0.2252 - val_accuracy: 0.8846\n",
      "Epoch 329/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2178 - accuracy: 0.9067 - val_loss: 0.2220 - val_accuracy: 0.8846\n",
      "Epoch 330/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.1898 - accuracy: 0.9241 - val_loss: 0.2217 - val_accuracy: 0.9038\n",
      "Epoch 331/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2246 - accuracy: 0.9241 - val_loss: 0.2248 - val_accuracy: 0.9038\n",
      "Epoch 332/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2155 - accuracy: 0.9154 - val_loss: 0.4089 - val_accuracy: 0.8462\n",
      "Epoch 333/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2197 - accuracy: 0.9176 - val_loss: 0.2268 - val_accuracy: 0.9038\n",
      "Epoch 334/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2062 - accuracy: 0.9111 - val_loss: 0.2827 - val_accuracy: 0.8846\n",
      "Epoch 335/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2001 - accuracy: 0.9197 - val_loss: 0.2235 - val_accuracy: 0.8846\n",
      "Epoch 336/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2112 - accuracy: 0.9089 - val_loss: 0.2295 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2010 - accuracy: 0.9241 - val_loss: 0.2453 - val_accuracy: 0.8654\n",
      "Epoch 338/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2082 - accuracy: 0.9111 - val_loss: 0.2434 - val_accuracy: 0.8654\n",
      "Epoch 339/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2300 - accuracy: 0.9154 - val_loss: 0.2303 - val_accuracy: 0.8846\n",
      "Epoch 340/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2009 - accuracy: 0.9197 - val_loss: 0.2572 - val_accuracy: 0.8654\n",
      "Epoch 341/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.2027 - accuracy: 0.9111 - val_loss: 0.3068 - val_accuracy: 0.8846\n",
      "Epoch 342/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.2233 - accuracy: 0.9176 - val_loss: 0.2735 - val_accuracy: 0.8846\n",
      "Epoch 343/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2042 - accuracy: 0.9132 - val_loss: 0.2450 - val_accuracy: 0.8846\n",
      "Epoch 344/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2065 - accuracy: 0.9111 - val_loss: 0.2150 - val_accuracy: 0.8846\n",
      "Epoch 345/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2261 - accuracy: 0.9219 - val_loss: 0.2329 - val_accuracy: 0.8846\n",
      "Epoch 346/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.1965 - accuracy: 0.9154 - val_loss: 0.2295 - val_accuracy: 0.8846\n",
      "Epoch 347/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2062 - accuracy: 0.9111 - val_loss: 0.2104 - val_accuracy: 0.8846\n",
      "Epoch 348/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2250 - accuracy: 0.9067 - val_loss: 0.2217 - val_accuracy: 0.9038\n",
      "Epoch 349/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2255 - accuracy: 0.9154 - val_loss: 0.2141 - val_accuracy: 0.8846\n",
      "Epoch 350/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2241 - accuracy: 0.9111 - val_loss: 0.2581 - val_accuracy: 0.8654\n",
      "Epoch 351/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2143 - accuracy: 0.9132 - val_loss: 0.2222 - val_accuracy: 0.9038\n",
      "Epoch 352/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.1982 - accuracy: 0.9132 - val_loss: 0.2647 - val_accuracy: 0.8654\n",
      "Epoch 353/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.1865 - accuracy: 0.9284 - val_loss: 0.2287 - val_accuracy: 0.8846\n",
      "Epoch 354/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2206 - accuracy: 0.9089 - val_loss: 0.2289 - val_accuracy: 0.8846\n",
      "Epoch 355/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2267 - accuracy: 0.9067 - val_loss: 0.2212 - val_accuracy: 0.8846\n",
      "Epoch 356/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2088 - accuracy: 0.9219 - val_loss: 0.2162 - val_accuracy: 0.9038\n",
      "Epoch 357/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2127 - accuracy: 0.9111 - val_loss: 0.2153 - val_accuracy: 0.9231\n",
      "Epoch 358/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.1909 - accuracy: 0.9219 - val_loss: 0.2683 - val_accuracy: 0.8846\n",
      "Epoch 359/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2186 - accuracy: 0.9046 - val_loss: 0.2117 - val_accuracy: 0.9038\n",
      "Epoch 360/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1981 - accuracy: 0.9219 - val_loss: 0.2617 - val_accuracy: 0.8654\n",
      "Epoch 361/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1996 - accuracy: 0.9219 - val_loss: 0.3754 - val_accuracy: 0.8462\n",
      "Epoch 362/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1954 - accuracy: 0.9262 - val_loss: 0.7169 - val_accuracy: 0.7308\n",
      "Epoch 363/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2113 - accuracy: 0.9241 - val_loss: 0.2195 - val_accuracy: 0.9038\n",
      "Epoch 364/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2129 - accuracy: 0.9132 - val_loss: 0.2565 - val_accuracy: 0.8846\n",
      "Epoch 365/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1871 - accuracy: 0.9154 - val_loss: 0.2458 - val_accuracy: 0.8846\n",
      "Epoch 366/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2195 - accuracy: 0.9241 - val_loss: 0.3244 - val_accuracy: 0.8654\n",
      "Epoch 367/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2266 - accuracy: 0.9067 - val_loss: 0.3006 - val_accuracy: 0.8654\n",
      "Epoch 368/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.1980 - accuracy: 0.9154 - val_loss: 0.2190 - val_accuracy: 0.9038\n",
      "Epoch 369/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.1963 - accuracy: 0.9349 - val_loss: 0.2389 - val_accuracy: 0.8846\n",
      "Epoch 370/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2296 - accuracy: 0.9111 - val_loss: 0.2321 - val_accuracy: 0.8846\n",
      "Epoch 371/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2020 - accuracy: 0.9262 - val_loss: 0.2112 - val_accuracy: 0.9038\n",
      "Epoch 372/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2059 - accuracy: 0.9132 - val_loss: 0.2098 - val_accuracy: 0.9038\n",
      "Epoch 373/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1981 - accuracy: 0.9241 - val_loss: 0.2096 - val_accuracy: 0.9038\n",
      "Epoch 374/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2119 - accuracy: 0.9111 - val_loss: 0.2292 - val_accuracy: 0.9038\n",
      "Epoch 375/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2069 - accuracy: 0.9111 - val_loss: 0.2516 - val_accuracy: 0.8654\n",
      "Epoch 376/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2257 - accuracy: 0.9111 - val_loss: 0.2503 - val_accuracy: 0.8654\n",
      "Epoch 377/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2094 - accuracy: 0.9111 - val_loss: 0.4505 - val_accuracy: 0.8462\n",
      "Epoch 378/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2439 - accuracy: 0.8980 - val_loss: 0.2393 - val_accuracy: 0.8846\n",
      "Epoch 379/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2324 - accuracy: 0.9132 - val_loss: 0.2244 - val_accuracy: 0.9038\n",
      "Epoch 380/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.2300 - accuracy: 0.9197 - val_loss: 0.2433 - val_accuracy: 0.9038\n",
      "Epoch 381/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2320 - accuracy: 0.9046 - val_loss: 0.2190 - val_accuracy: 0.9038\n",
      "Epoch 382/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2038 - accuracy: 0.9241 - val_loss: 0.2068 - val_accuracy: 0.9038\n",
      "Epoch 383/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.2282 - accuracy: 0.9176 - val_loss: 0.2908 - val_accuracy: 0.8654\n",
      "Epoch 384/500\n",
      "461/461 [==============================] - 0s 107us/step - loss: 0.1861 - accuracy: 0.9176 - val_loss: 0.2152 - val_accuracy: 0.9038\n",
      "Epoch 385/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2060 - accuracy: 0.9197 - val_loss: 0.2650 - val_accuracy: 0.8654\n",
      "Epoch 386/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2073 - accuracy: 0.9154 - val_loss: 0.2775 - val_accuracy: 0.8846\n",
      "Epoch 387/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2079 - accuracy: 0.9089 - val_loss: 0.2180 - val_accuracy: 0.9038\n",
      "Epoch 388/500\n",
      "461/461 [==============================] - 0s 133us/step - loss: 0.2038 - accuracy: 0.9154 - val_loss: 0.2128 - val_accuracy: 0.9038\n",
      "Epoch 389/500\n",
      "461/461 [==============================] - 0s 116us/step - loss: 0.2012 - accuracy: 0.9197 - val_loss: 0.2155 - val_accuracy: 0.9038\n",
      "Epoch 390/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2271 - accuracy: 0.9046 - val_loss: 0.2394 - val_accuracy: 0.8846\n",
      "Epoch 391/500\n",
      "461/461 [==============================] - 0s 108us/step - loss: 0.2065 - accuracy: 0.9219 - val_loss: 0.2430 - val_accuracy: 0.8846\n",
      "Epoch 392/500\n",
      "461/461 [==============================] - 0s 109us/step - loss: 0.2120 - accuracy: 0.9262 - val_loss: 0.4013 - val_accuracy: 0.8462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/500\n",
      "461/461 [==============================] - 0s 110us/step - loss: 0.2119 - accuracy: 0.9089 - val_loss: 0.2334 - val_accuracy: 0.8846\n",
      "Epoch 394/500\n",
      "461/461 [==============================] - 0s 148us/step - loss: 0.2305 - accuracy: 0.9024 - val_loss: 0.2677 - val_accuracy: 0.8846\n",
      "Epoch 395/500\n",
      "461/461 [==============================] - 0s 145us/step - loss: 0.2116 - accuracy: 0.9067 - val_loss: 0.2147 - val_accuracy: 0.9038\n",
      "Epoch 396/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.1897 - accuracy: 0.9284 - val_loss: 0.2146 - val_accuracy: 0.9231\n",
      "Epoch 397/500\n",
      "461/461 [==============================] - 0s 107us/step - loss: 0.2193 - accuracy: 0.9132 - val_loss: 0.2384 - val_accuracy: 0.8846\n",
      "Epoch 398/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2203 - accuracy: 0.9132 - val_loss: 0.2240 - val_accuracy: 0.8846\n",
      "Epoch 399/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2080 - accuracy: 0.9089 - val_loss: 0.2179 - val_accuracy: 0.9038\n",
      "Epoch 400/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1974 - accuracy: 0.9349 - val_loss: 0.2273 - val_accuracy: 0.8846\n",
      "Epoch 401/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2102 - accuracy: 0.9067 - val_loss: 0.2366 - val_accuracy: 0.8846\n",
      "Epoch 402/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2120 - accuracy: 0.9111 - val_loss: 0.4013 - val_accuracy: 0.8462\n",
      "Epoch 403/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1985 - accuracy: 0.9219 - val_loss: 0.2084 - val_accuracy: 0.9038\n",
      "Epoch 404/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2316 - accuracy: 0.9046 - val_loss: 0.2497 - val_accuracy: 0.8654\n",
      "Epoch 405/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2199 - accuracy: 0.9132 - val_loss: 0.2434 - val_accuracy: 0.8846\n",
      "Epoch 406/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1922 - accuracy: 0.9219 - val_loss: 0.2244 - val_accuracy: 0.9038\n",
      "Epoch 407/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.1998 - accuracy: 0.9176 - val_loss: 0.2309 - val_accuracy: 0.8846\n",
      "Epoch 408/500\n",
      "461/461 [==============================] - 0s 107us/step - loss: 0.2253 - accuracy: 0.9024 - val_loss: 0.2947 - val_accuracy: 0.8846\n",
      "Epoch 409/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2172 - accuracy: 0.9046 - val_loss: 0.3170 - val_accuracy: 0.9038\n",
      "Epoch 410/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.2274 - accuracy: 0.9067 - val_loss: 0.2536 - val_accuracy: 0.8654\n",
      "Epoch 411/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2172 - accuracy: 0.9111 - val_loss: 0.2206 - val_accuracy: 0.9038\n",
      "Epoch 412/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.2013 - accuracy: 0.9262 - val_loss: 0.2182 - val_accuracy: 0.9231\n",
      "Epoch 413/500\n",
      "461/461 [==============================] - 0s 107us/step - loss: 0.2095 - accuracy: 0.9176 - val_loss: 0.2204 - val_accuracy: 0.9038\n",
      "Epoch 414/500\n",
      "461/461 [==============================] - 0s 107us/step - loss: 0.2062 - accuracy: 0.9306 - val_loss: 0.2435 - val_accuracy: 0.8846\n",
      "Epoch 415/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.1964 - accuracy: 0.9197 - val_loss: 0.2333 - val_accuracy: 0.8846\n",
      "Epoch 416/500\n",
      "461/461 [==============================] - 0s 107us/step - loss: 0.2109 - accuracy: 0.9219 - val_loss: 0.2208 - val_accuracy: 0.8846\n",
      "Epoch 417/500\n",
      "461/461 [==============================] - 0s 108us/step - loss: 0.2256 - accuracy: 0.9089 - val_loss: 0.2439 - val_accuracy: 0.8846\n",
      "Epoch 418/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1873 - accuracy: 0.9219 - val_loss: 0.2371 - val_accuracy: 0.8654\n",
      "Epoch 419/500\n",
      "461/461 [==============================] - 0s 108us/step - loss: 0.2147 - accuracy: 0.9176 - val_loss: 0.2397 - val_accuracy: 0.8654\n",
      "Epoch 420/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2041 - accuracy: 0.9154 - val_loss: 0.2343 - val_accuracy: 0.8846\n",
      "Epoch 421/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.1948 - accuracy: 0.9154 - val_loss: 0.2288 - val_accuracy: 0.8846\n",
      "Epoch 422/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2086 - accuracy: 0.9262 - val_loss: 0.2180 - val_accuracy: 0.9038\n",
      "Epoch 423/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.1952 - accuracy: 0.9262 - val_loss: 0.2228 - val_accuracy: 0.9038\n",
      "Epoch 424/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.1865 - accuracy: 0.9349 - val_loss: 0.2499 - val_accuracy: 0.8654\n",
      "Epoch 425/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.1995 - accuracy: 0.9219 - val_loss: 0.2180 - val_accuracy: 0.9038\n",
      "Epoch 426/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.1936 - accuracy: 0.9176 - val_loss: 0.2173 - val_accuracy: 0.9231\n",
      "Epoch 427/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2062 - accuracy: 0.9219 - val_loss: 0.2145 - val_accuracy: 0.9038\n",
      "Epoch 428/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2116 - accuracy: 0.9154 - val_loss: 0.2177 - val_accuracy: 0.9038\n",
      "Epoch 429/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2013 - accuracy: 0.9262 - val_loss: 0.2066 - val_accuracy: 0.9038\n",
      "Epoch 430/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2375 - accuracy: 0.9197 - val_loss: 0.2660 - val_accuracy: 0.8654\n",
      "Epoch 431/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.1871 - accuracy: 0.9306 - val_loss: 0.2307 - val_accuracy: 0.9038\n",
      "Epoch 432/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2044 - accuracy: 0.9284 - val_loss: 0.2415 - val_accuracy: 0.8846\n",
      "Epoch 433/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1985 - accuracy: 0.9241 - val_loss: 0.2412 - val_accuracy: 0.8846\n",
      "Epoch 434/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2390 - accuracy: 0.8980 - val_loss: 0.2317 - val_accuracy: 0.9038\n",
      "Epoch 435/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2012 - accuracy: 0.9197 - val_loss: 0.2099 - val_accuracy: 0.9038\n",
      "Epoch 436/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.1796 - accuracy: 0.9262 - val_loss: 0.2436 - val_accuracy: 0.8846\n",
      "Epoch 437/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2033 - accuracy: 0.9262 - val_loss: 0.2850 - val_accuracy: 0.8654\n",
      "Epoch 438/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2007 - accuracy: 0.9197 - val_loss: 0.2251 - val_accuracy: 0.8846\n",
      "Epoch 439/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2000 - accuracy: 0.9176 - val_loss: 0.3110 - val_accuracy: 0.8654\n",
      "Epoch 440/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2034 - accuracy: 0.9241 - val_loss: 0.2410 - val_accuracy: 0.8654\n",
      "Epoch 441/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2120 - accuracy: 0.9197 - val_loss: 0.2132 - val_accuracy: 0.9038\n",
      "Epoch 442/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2054 - accuracy: 0.9089 - val_loss: 0.2102 - val_accuracy: 0.9231\n",
      "Epoch 443/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2165 - accuracy: 0.9089 - val_loss: 0.2303 - val_accuracy: 0.9038\n",
      "Epoch 444/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2093 - accuracy: 0.9241 - val_loss: 0.2147 - val_accuracy: 0.9038\n",
      "Epoch 445/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2015 - accuracy: 0.9241 - val_loss: 0.2407 - val_accuracy: 0.8846\n",
      "Epoch 446/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2045 - accuracy: 0.9197 - val_loss: 0.2148 - val_accuracy: 0.9231\n",
      "Epoch 447/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2192 - accuracy: 0.9262 - val_loss: 0.2291 - val_accuracy: 0.9038\n",
      "Epoch 448/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2167 - accuracy: 0.9176 - val_loss: 0.2124 - val_accuracy: 0.9038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/500\n",
      "461/461 [==============================] - 0s 107us/step - loss: 0.2076 - accuracy: 0.9284 - val_loss: 0.2351 - val_accuracy: 0.8846\n",
      "Epoch 450/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2061 - accuracy: 0.9241 - val_loss: 0.2211 - val_accuracy: 0.9038\n",
      "Epoch 451/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2051 - accuracy: 0.9219 - val_loss: 0.2213 - val_accuracy: 0.9038\n",
      "Epoch 452/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.1959 - accuracy: 0.9132 - val_loss: 0.2070 - val_accuracy: 0.9038\n",
      "Epoch 453/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2422 - accuracy: 0.9024 - val_loss: 0.2170 - val_accuracy: 0.9038\n",
      "Epoch 454/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2124 - accuracy: 0.9024 - val_loss: 0.2301 - val_accuracy: 0.9038\n",
      "Epoch 455/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1856 - accuracy: 0.9284 - val_loss: 0.2269 - val_accuracy: 0.9038\n",
      "Epoch 456/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1840 - accuracy: 0.9306 - val_loss: 0.2434 - val_accuracy: 0.8654\n",
      "Epoch 457/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1842 - accuracy: 0.9241 - val_loss: 0.3426 - val_accuracy: 0.8654\n",
      "Epoch 458/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2154 - accuracy: 0.9176 - val_loss: 0.2248 - val_accuracy: 0.9231\n",
      "Epoch 459/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1992 - accuracy: 0.9241 - val_loss: 0.2395 - val_accuracy: 0.8654\n",
      "Epoch 460/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2460 - accuracy: 0.9089 - val_loss: 0.2577 - val_accuracy: 0.8654\n",
      "Epoch 461/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2067 - accuracy: 0.9154 - val_loss: 0.2448 - val_accuracy: 0.8846\n",
      "Epoch 462/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.1940 - accuracy: 0.9306 - val_loss: 0.2177 - val_accuracy: 0.9038\n",
      "Epoch 463/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2155 - accuracy: 0.9067 - val_loss: 0.3093 - val_accuracy: 0.8846\n",
      "Epoch 464/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.1955 - accuracy: 0.9154 - val_loss: 0.2109 - val_accuracy: 0.8846\n",
      "Epoch 465/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2015 - accuracy: 0.9154 - val_loss: 0.2352 - val_accuracy: 0.8846\n",
      "Epoch 466/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1959 - accuracy: 0.9219 - val_loss: 0.2084 - val_accuracy: 0.9038\n",
      "Epoch 467/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.1854 - accuracy: 0.9241 - val_loss: 0.2281 - val_accuracy: 0.8846\n",
      "Epoch 468/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2342 - accuracy: 0.8959 - val_loss: 0.2604 - val_accuracy: 0.8654\n",
      "Epoch 469/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2002 - accuracy: 0.9197 - val_loss: 0.3182 - val_accuracy: 0.8846\n",
      "Epoch 470/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2075 - accuracy: 0.9219 - val_loss: 0.2388 - val_accuracy: 0.8846\n",
      "Epoch 471/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1706 - accuracy: 0.9262 - val_loss: 0.2618 - val_accuracy: 0.9038\n",
      "Epoch 472/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2036 - accuracy: 0.9197 - val_loss: 0.2181 - val_accuracy: 0.9038\n",
      "Epoch 473/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2324 - accuracy: 0.9002 - val_loss: 0.2604 - val_accuracy: 0.8846\n",
      "Epoch 474/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.2029 - accuracy: 0.9154 - val_loss: 0.2294 - val_accuracy: 0.8846\n",
      "Epoch 475/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.1942 - accuracy: 0.9176 - val_loss: 0.2175 - val_accuracy: 0.9038\n",
      "Epoch 476/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.2070 - accuracy: 0.9197 - val_loss: 0.2138 - val_accuracy: 0.9231\n",
      "Epoch 477/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.1949 - accuracy: 0.9197 - val_loss: 0.2178 - val_accuracy: 0.9038\n",
      "Epoch 478/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.1909 - accuracy: 0.9197 - val_loss: 0.2280 - val_accuracy: 0.9038\n",
      "Epoch 479/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.1860 - accuracy: 0.9197 - val_loss: 0.2083 - val_accuracy: 0.9038\n",
      "Epoch 480/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2016 - accuracy: 0.9067 - val_loss: 0.3061 - val_accuracy: 0.8846\n",
      "Epoch 481/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2109 - accuracy: 0.9024 - val_loss: 0.2144 - val_accuracy: 0.9231\n",
      "Epoch 482/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2127 - accuracy: 0.9154 - val_loss: 0.2204 - val_accuracy: 0.9231\n",
      "Epoch 483/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2223 - accuracy: 0.9024 - val_loss: 0.2261 - val_accuracy: 0.9231\n",
      "Epoch 484/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.1898 - accuracy: 0.9306 - val_loss: 0.2085 - val_accuracy: 0.9038\n",
      "Epoch 485/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.1879 - accuracy: 0.9262 - val_loss: 0.2609 - val_accuracy: 0.8654\n",
      "Epoch 486/500\n",
      "461/461 [==============================] - 0s 101us/step - loss: 0.1935 - accuracy: 0.9132 - val_loss: 0.2421 - val_accuracy: 0.8654\n",
      "Epoch 487/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1957 - accuracy: 0.9262 - val_loss: 0.2400 - val_accuracy: 0.8846\n",
      "Epoch 488/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1972 - accuracy: 0.9176 - val_loss: 0.2087 - val_accuracy: 0.9038\n",
      "Epoch 489/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.1972 - accuracy: 0.9284 - val_loss: 0.2108 - val_accuracy: 0.9038\n",
      "Epoch 490/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1911 - accuracy: 0.9132 - val_loss: 0.2318 - val_accuracy: 0.8846\n",
      "Epoch 491/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2159 - accuracy: 0.9111 - val_loss: 0.2104 - val_accuracy: 0.9231\n",
      "Epoch 492/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1901 - accuracy: 0.9154 - val_loss: 0.2620 - val_accuracy: 0.8846\n",
      "Epoch 493/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1861 - accuracy: 0.9089 - val_loss: 0.2418 - val_accuracy: 0.8846\n",
      "Epoch 494/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.1922 - accuracy: 0.9262 - val_loss: 0.2179 - val_accuracy: 0.9038\n",
      "Epoch 495/500\n",
      "461/461 [==============================] - 0s 106us/step - loss: 0.2646 - accuracy: 0.9024 - val_loss: 0.2284 - val_accuracy: 0.9038\n",
      "Epoch 496/500\n",
      "461/461 [==============================] - 0s 107us/step - loss: 0.1913 - accuracy: 0.9219 - val_loss: 0.2275 - val_accuracy: 0.8846\n",
      "Epoch 497/500\n",
      "461/461 [==============================] - 0s 104us/step - loss: 0.2029 - accuracy: 0.9306 - val_loss: 0.2207 - val_accuracy: 0.9038\n",
      "Epoch 498/500\n",
      "461/461 [==============================] - 0s 105us/step - loss: 0.2171 - accuracy: 0.9089 - val_loss: 0.2122 - val_accuracy: 0.9038\n",
      "Epoch 499/500\n",
      "461/461 [==============================] - 0s 103us/step - loss: 0.1869 - accuracy: 0.9328 - val_loss: 0.3046 - val_accuracy: 0.8846\n",
      "Epoch 500/500\n",
      "461/461 [==============================] - 0s 102us/step - loss: 0.2211 - accuracy: 0.9111 - val_loss: 0.2202 - val_accuracy: 0.9038\n"
     ]
    }
   ],
   "source": [
    "#training our ANN Model\n",
    "history = classifier.fit(X_train, \n",
    "                         Y_train, \n",
    "                         batch_size = 16, \n",
    "                         epochs = 500, \n",
    "                         validation_split=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "sLe6qemayUY4",
    "outputId": "4f3e8378-c738-4207-8c2f-cbcadc0b0384"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.4163496e-01]\n",
      " [3.8907290e-01]\n",
      " [9.7365999e-01]\n",
      " [6.7952275e-03]\n",
      " [1.4174521e-02]\n",
      " [7.9986823e-01]\n",
      " [9.0889496e-01]\n",
      " [9.8771608e-01]\n",
      " [2.9802322e-07]\n",
      " [9.9134064e-01]\n",
      " [9.0967190e-01]\n",
      " [9.8658764e-01]\n",
      " [9.9234152e-01]\n",
      " [8.6085236e-01]\n",
      " [9.5550251e-01]\n",
      " [9.3847322e-01]\n",
      " [9.4265825e-01]\n",
      " [9.1038167e-01]\n",
      " [9.1247225e-01]\n",
      " [7.6398885e-01]\n",
      " [2.9668570e-02]\n",
      " [9.9332774e-01]\n",
      " [1.4157295e-03]\n",
      " [9.3784571e-01]\n",
      " [9.8694491e-01]\n",
      " [9.8633736e-01]\n",
      " [9.9200982e-01]\n",
      " [9.8744702e-01]\n",
      " [8.9804339e-01]\n",
      " [8.6825716e-01]\n",
      " [9.4830704e-01]\n",
      " [9.3208295e-01]\n",
      " [8.7038791e-01]\n",
      " [9.8889208e-01]\n",
      " [9.9408537e-01]\n",
      " [9.8449063e-01]\n",
      " [8.5549456e-01]\n",
      " [9.8855484e-01]\n",
      " [9.8934782e-01]\n",
      " [9.5058751e-01]\n",
      " [9.9302089e-01]\n",
      " [9.5658791e-01]\n",
      " [9.9372470e-01]\n",
      " [9.9248028e-01]\n",
      " [9.8730367e-01]\n",
      " [9.4919109e-01]\n",
      " [9.8831046e-01]\n",
      " [9.2496645e-01]\n",
      " [9.8804772e-01]\n",
      " [8.4874004e-01]\n",
      " [3.0142665e-03]\n",
      " [9.5844269e-05]\n",
      " [2.1317005e-03]\n",
      " [4.0534317e-01]\n",
      " [6.1255693e-04]\n",
      " [9.1146761e-01]]\n",
      "[[ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]]\n",
      "Accuracy Score: 0.9642857142857143\n",
      "Precision Score: 0.9555555555555556\n",
      "Recall Score: 1.0\n",
      "F1 Score: 0.9772727272727273\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        13\n",
      "           1       0.96      1.00      0.98        43\n",
      "\n",
      "    accuracy                           0.96        56\n",
      "   macro avg       0.98      0.92      0.95        56\n",
      "weighted avg       0.97      0.96      0.96        56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Part 3 - Making predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "ann_pred = classifier.predict(X_test)\n",
    "print(ann_pred)\n",
    "ann_pred = (ann_pred > 0.5)\n",
    "print(ann_pred)\n",
    "#Model Evaluation\n",
    "ann = accuracy_score(Y_test, ann_pred)\n",
    "print('Accuracy Score: ' + str(ann))\n",
    "\n",
    "print('Precision Score: ' + str(precision_score(Y_test, ann_pred)))\n",
    "\n",
    "print('Recall Score: ' + str(recall_score(Y_test, ann_pred)))\n",
    "\n",
    "print('F1 Score: ' + str(f1_score(Y_test, ann_pred)))\n",
    "\n",
    "print('Classification Report: \\n' + str(classification_report(Y_test, ann_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x7fb055f828d0>"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEJCAYAAAB7UTvrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABBp0lEQVR4nO3deXhM1//A8fckIyIbyQShsVRQDW0saRGkjUSq1QW/Fq22lrb0q5ZSWpTSxVKt2rdaYvn2W0WLqqINSoOithZVCUWZyGrJHpO5vz/S3BrZbiKTyfJ5PY/nmblz7r2fI8n9zD3n3HN0iqIoCCGEEICdrQMQQghRdkhSEEIIoZKkIIQQQiVJQQghhEqSghBCCJUkBSGEECq9rQO4W0ajsVj7eXp6Eh8fX8LRlG1S58pB6lw53E2d69atm+9ncqcghBBCJUlBCCGEqtDmI5PJRGRkJBcvXiQlJQVnZ2caNGhAkyZN0OvLfeuTEEKI2+R7Vb958yabNm1iz549uLi4cM899+Do6Eh6ejrbtm0jOTmZRx55hO7du+Pm5laaMQshhLCSfJPCpEmTCAoK4pNPPsHDwyPX54mJiURERDBp0iRmzZpl1SCFEEKUjnyTwieffFJg85CHhwdPP/00TzzxRKEnWbhwIUePHqV69erMnDkz1+eKohAWFsaxY8eoWrUqQ4YMoVGjRhqrIIQQoqTk29Gstb9AS7lHH32U8ePH5/v5sWPHuHr1KnPnzmXQoEEsW7ZM07mFEEKUrGL3FJtMJqZMmcKkSZMKLevr60tsbGy+n//6668EBgai0+lo2rQpKSkpXLt2DXd39+KGV+EoJhNc/Rvl4jmIjynWMZKrOWFOSy3hyMo2qXPlUBnrnNGmHXj7lPhxi50UFEXh9OnTJRJEYmIinp6e6nuDwUBiYmKeSSE8PJzw8HAApk+fbrFfUej1+mLva23KrUxMl85z69yfmM79ya3zf5J18Rzcyvy3kE5X5OOmlGCM5YXUuXKojHU2OTri2bJtiR+3wKQwdOjQfD8rybV58jqWLp+LXkhICCEhIer74j7RV1aegFQyM+Dvv1AunYdL51AuRoHxEmRlZRdwcob6PuiCukH9Ruga+ECtuujsiv6ISVmpc2mSOlcOlbHOzlZ6ornApJCcnMxLL71ErVq1cn1mMpmYPn16sQK6k8FgsKhcQkJChWw6UtJT4e8L2Rf+S+eyE0H032A2ZxdwcYX6jdGFtkbXoDHU9wHP2vkmSCGEKGkFJoV7770XBwcHHnjggVyf3bp1q8SC8Pf3Z/v27XTo0IHIyEicnJzKfVJQUpPh0nmUS+fg4nmUS1EQY4Scu6Lq7tl3AK3aoavvAw18wN1TEoAQwqYKTArPPvssVatWzXtHvV5TJzPA7NmzOX36NElJSbz++uv06tULk8kEQGhoKK1ateLo0aMMHz4cBwcHhgwZUsRqlC1Z8z+CE4f+3eDhmZ0A2j6SnQDq+6CrkfvZDyGEsLUCk0Lz5s3z/Uyn0+Hr66vpJG+++WaBn+t0Ol599VVNxyoXzp2BJr7Ydeud3Q/gWt3WEQkhhCYyeZGV6O5piK55K1uHIYQQRSKzpAohhFBJUhBCCKGSpCCEEEIlSUEIIYRKc1IYMGBArm39+vUr0WCEEELYluak8M477+TaNm7cuBINRgghhG1pTgrNmjXTtE0IIUT5le9zCidPntR0gBYtWpRYMEIIIWwr36SwaNGiQnfW6XTMnz+/RAMSQghhO/kmhQULFpRmHEIIIcoAzX0KJpOJP/74g/379wOQnp5Oenq61QITQghR+jTNfXTp0iU+/vhjqlSpQkJCAgEBAZw+fZo9e/YwcuRIa8cohBCilGi6U1i6dCm9e/dm9uzZ6PXZecTX15czZ85YNTghhBClS1NSuHz5Mp06dbLY5ujoSGZmZj57CCGEKI80JYWaNWty/vx5i21RUVF4eXlZJSghhBC2oalPoXfv3kyfPp0uXbpgMpnYuHEjP/74I4MHD7Z2fEIIIUqRpjuFNm3aMG7cOG7evImvry9xcXGMHj0aPz8/a8cnhBCiFGleea1Ro0Y0atTImrEIIYSwMU1JwWQy8fXXX7Nv3z6uXbuGu7s7AQEB9OzZEwcHB2vHKIQQopRoSgpLly7FaDQyYMAAatasSVxcHJs2bWLZsmUMGTLE2jEKIYQoJZqSwuHDh5k3bx7Ozs4AeHt706RJE4YNG2bV4IQQQpQuTR3NNWrUICMjw2JbZmYm7u7uVglKCCGEbWiaOjswMJCpU6fStWtXDAYDCQkJ7Nixg8DAwFIJUgghROko0tTZGzdutHgfHh5O9+7dSzwoIYQQtiFTZwshhFBpnjpbCCFExadp9FFqairr16/n9OnTJCUloSiK+pmWFdqEEEKUD5ruFJYtW8Zff/3Fs88+S3JyMgMHDsTT05Nu3bpZOz4hhBClSFNS+O2333jrrbd46KGHsLOz46GHHmLkyJH8/PPP1o5PCCFEKdKUFBRFwcnJCcheRyElJYUaNWpw9epVqwZXfimFFxFCiDJIU59CgwYNOH36NA888ADNmjVj+fLlODo6UqdOHc0nOn78OGFhYZjNZoKDg3MNZU1NTWXu3LkkJCSQlZXFU089RVBQUJEqUxYoJhOkpoCTs61DEUKIItN0pzB48GBq1qwJwMCBA3FwcCAlJYWhQ4dqOonZbGb58uWMHz+eWbNmsW/fPi5fvmxRZvv27Xh7e/PJJ58wefJkVq9ejclkKmJ1yoCEWDCboVZdW0cihBBFpulOoXbt2uprNzc3Xn/99SKdJGeVtpzjBAQEcPjwYby9vdUyOp2O9PR0FEUhPT0dFxcX7OzK4YjZWCMAutra76KEEKKsyDcp7Nq1S9MBOnfuXGiZxMREDAaD+t5gMBAZGWlRpmvXrsyYMYPBgweTlpbGyJEj80wK4eHhhIeHAzB9+nQ8PT01xXknvV5f7H0LkpJ8g2TAcP8D2FUvW3NDWavOZZnUuXKQOpfgcfP7QOvIIi1J4fbnGnLodDqL9ydOnKBBgwa89957xMTE8OGHH9KsWTO1gztHSEgIISEh6vv4+HhNcd7J09Oz2PsWxHw+Eqo5k5BpQmeF498Na9W5LJM6Vw5S56KpWzf/5u18k8KkSZOKdbK85EyilyMhISHXDKu7d++me/fu6HQ6vLy8qFWrFkajkcaNG5dYHKVBiTVCrTq5kp4QQpQHpdJo7+PjQ3R0NLGxsZhMJvbv34+/v79FGU9PT37//XcArl+/jtFopFatWqURXsmKMaKrLZ3MQojySfMazXfD3t6egQMHMmXKFMxmM0FBQdSrV48ffvgBgNDQUP7v//6PhQsX8tZbbwHQt29f3NzcSiO8EqPcyoTEOAgovElNCCHKolJJCgCtW7emdevWFttCQ0PV1x4eHkyYMKG0wrGOuKugKDIcVQhRbpXDMZ9lmDocVZKCEKJ80nyncPnyZX755ReuX7/Oq6++ypUrVzCZTDRo0MCa8ZUrSkx09gu5UxBClFOa7hQOHDjA5MmTSUxMVIeqpqens3r1aqsGV+7EXAEXN3TOLraORAghikXTncK6deuYMGECDRs25MCBA0D2fEgXLlywZmzljhIbDdJ0JIQoxzTdKdy4cSNXM5FOp5Ox+HeKMaKrJdNbCCHKL01JoVGjRuzdu9di2759+8rdg2XWpGSkw/UEqH2PrUMRQohi09R8NGDAAD766CN27dpFRkYGU6ZMwWg0lv8hpCUpVjqZhRDln6akcM899zB79myOHDlCmzZtMBgMtGnTBkdHR2vHV37I7KhCiApAU1I4dOgQbdq0ISAgwNrxlFtKTHZSQPoUhBDlmKY+hfXr1/Pqq6+yePFiTp06Ze2YyqdYI1T3QOfoVHhZIYQoozTdKXzyySdcvnyZiIgIFi9ezK1btwgICKBjx440atTI2jGWC0qMEaTpSAhRzmme5sLb25s+ffowb948Ro0axaVLlxg3bpw1YytfYozopJNZCFHOFWlCvPj4ePbv309ERARxcXEEBQVZK65yRUlLhaQbMvJICFHuaUoKO3bsICIigosXL9KqVSueffZZWrdujV5fapOslm0yEZ4QooLQdFU/cuQIXbp04eGHH5ZhqHlQrl7JfiFJQQhRzmlKCuPHj7d2HOVbzoNrNb1sG4cQQtylfJPCkiVLGDx4MADz58/P9wBDhw4t+ajKm1gjeHiic6hq60iEEOKu5JsUbl8fuXbt2qUSTHmVPRxV5jwSQpR/+SaFHj16qK+7dOlCjRo1cpW5fv26NWIqf2KM6B7qaOsohBDirml6TmHEiBF5bh85cmSJBlMeKck3ITVZhqMKISoETUlBUZRc21JTU7GzkyWeiZHhqEKIiqPA0Uf/+c9/AMjMzFRf50hOTqZDhw7Wi6ycUHJGHklSEEJUAAUmhWHDhqEoCtOmTWPYsGEWn9WoUYO6deVCSMwV0NmBp3TGCyHKvwKTgq+vLwDLly+nalUZbpmn2GjwrIVOX8XWkQghxF3LNyl888039OzZE4BNmzble4DevXuXeFDliRJjlDUUhBAVRr5JISEhIc/X4l+KomQPR218v61DEUKIEpFvUnjttdfU10OGDCmVYMqdm9chI02GowohKgxNcx9dvnwZFxcXatSoQXp6Ot9++y12dnY89dRTlbuvIUbWZRZCVCyaHjSYM2cOqampAKxevZo//viDs2fP8vnnn1s1uLJOic1Zl1nuFIQQFYOmO4W4uDjq1q2LoigcPnyYmTNn4uDgIJPhxRjBXg+GWoWXFUKIckBTUqhSpQppaWlcvnwZg8GAm5sbWVlZ3Lp1S/OJjh8/TlhYGGazmeDgYLp3756rzKlTp1i5ciVZWVm4urry/vvvaz6+LSixRqhZG529va1DEUKIEqEpKXTo0IEPPviAtLQ0unbtCsBff/1lMZNqQcxmM8uXL2fChAkYDAbGjRuHv78/3t7eapmUlBSWLVvGu+++i6enJzdu3ChGdUpZjFGajoQQFYqmpNC/f39OnDiBvb09LVq0AECn09GvXz9NJ4mKisLLy0udgjsgIIDDhw9bJIWIiAjatm2Lp6cnANWrVy9SRUqbYjZDXDS6+1vaOhQhhCgxmhdZ9vPzIz4+nrNnz+Lh4YGPj4/mkyQmJmIwGNT3BoOByMhIizLR0dGYTCYmT55MWloaTzzxBI888kiuY4WHhxMeHg7A9OnT1SRSVHq9vtj7AmTFxxCfmYmLT1Oc7uI4pelu61weSZ0rB6lzCR5XS6Fr164xe/ZsIiMjcXFxISkpiaZNmzJixAg8PDwK3T+vWVZ1Op3F+6ysLP766y8mTpxIZmYmEyZMoEmTJrnmVwoJCSEkJER9Hx8fr6UKuXh6ehZ7XwDlj5MApDi7kXoXxylNd1vn8kjqXDlInYumoHnrNA1JXbp0KQ0aNGDFihV8/vnnhIWF0bBhQ5YuXaopAIPBkOsJaXd391xl/Pz8cHR0xM3Njfvvv5+LFy9qOr4tqLOjSp+CEKIC0ZQU/vzzT15++WUcHR0BcHR05MUXX+Ts2bOaTuLj40N0dDSxsbGYTCb279+Pv7+/RRl/f3/OnDlDVlYWGRkZREVFcc89ZXiJy1gjVHEAd0PhZYUQopzQ1Hzk7OzM5cuXadiwobrNaDTi5OSk6ST29vYMHDiQKVOmYDabCQoKol69evzwww8AhIaG4u3tTcuWLRk9ejR2dnZ07tyZ+vXrF71GpSRnIjydLDQkhKhANCWFp59+mg8//JDOnTtTs2ZN4uLi+Omnn4o0Q2rr1q1p3bq1xbbQ0NBc53n66ac1H9OmYoxQx7vwckIIUY5oSgohISF4eXkRERHBpUuXcHd3Z8SIEerw1MpGMWdB/FV0fg/bOhQhhChRBSYFRVHYuXMnly5dolGjRrz++uulFVfZlhAHJpMswSmEqHAKbBBfs2YN69at4/r16/zvf/9j3bp1pRVX2abOjipJQQhRsRR4p3DgwAEmT55M3bp1uXz5MjNmzKBXr16lFVuZJbOjCiEqqgLvFFJTU9WHHLy9vUlOTi6VoMq82GioWg2quxdeVgghypFC+xRiY2PVJ5LNZrPFe0Cdz6gyUWKMULtOrqeyhRCivCswKWRkZDBs2DCLbXe+/+qrr0o+qrIu5gq6Bo1tHYUQQpS4ApNCpbzgF0IxmSAhFh4KtHUoQghR4uRx3KKKjwGzGWRdZiFEBZRvUvj000+JiooqcOeoqCg+/fTTEg+qTIvNGY5ahudlEkKIYsq3+ahLly4sX76c1NRUfH19qVu3LtWqVSMtLY3o6GhOnTqFs7Mzffr0Kc14bU6JkeGoQoiKK9+k4Ofnh5+fH+fOnePYsWNERkaSmpqKs7MzDRo04M033+Tee+8tzVjLhlgjODmDi6utIxFCiBJX6NxHPj4+RVplraJT/lmXWYajCiEqIuloLqrYaJneQghRYUlSKALlViYkxkl/ghCiwpKkUBSxV0FRZHZUIUSFJUmhKHKGo8qdghCigtK0yA7Ab7/9xr59+7hx4wZjx47l3LlzpKWlVaqFdtTZUeXBNSFEBaXpTmHbtm0sXbqUOnXq8McffwDg4ODA2rVrrRpcmRNjBNfq6JxcbB2JEEJYhaak8P333zNx4kS6d++O3T8L1d9zzz0YjUarBlfWZA9HlbsEIUTFpSkppKWl4enpabHNZDKh12tufaoYYo3SnyCEqNA0JYX777+fTZs2WWzbtm0bzZs3t0ZMZZKSngbXE2XkkRCiQtOUFAYOHMihQ4d44403SE9PZ8SIEfzyyy/069fP2vGVHbHRgKzLLISo2DS1/7i7uzNt2jTOnTtHXFwcBoOBxo0bq/0LlYKsyyyEqAQ0XdVnzJiBTqejcePGtG/fnqZNm2JnZ1epps3+d3ZU6WgWQlRcmpLCqVOnirS9QoqNhhoe6Byr2ToSIYSwGk3LcZpMplxLc8bExFCzZk3rRVbGKDFXpOlICFHhFZgUEhISADCbzerrHJ6envTq1ct6kZU1sdHoWra1dRRCCGFVBSaFIUOGANC0aVNCQkJKJaCySElNgaQb0p8ghKjwNI0+ykkIaWlpJCUloSiK+lnt2rWtE1lZIusyCyEqCU1J4fLly8ydO5eLFy/m+uzOvoaKSNZlFkJUFppGHy1btozmzZuzYsUKnJycCAsLo0uXLrzxxhuaT3T8+HFGjBjBsGHDcj0dfbuoqCh69+7NL7/8ovnYVhdjBJ0OannZOhIhhLAqTUnh4sWL9O3bF2dnZxRFwcnJiRdffFHzXYLZbGb58uWMHz+eWbNmsW/fPi5fvpxnuS+++IKWLVsWqRJWF2sEd090VRxsHYkQQliVpqRQpUoVsrKyAHB1dSU+Ph5FUUhOTtZ0kqioKLy8vKhduzZ6vZ6AgAAOHz6cq9y2bdto27Ytbm5uRaiC9SkxRpnzSAhRKWjqU2jWrBkHDhzg0UcfpV27dkydOpUqVaponhAvMTERg8GgvjcYDERGRuYqc+jQISZNmsSiRYvyPVZ4eDjh4eEATJ8+PdfsrVrp9XpN+yqKQlzcVRw7heBWzHOVFVrrXJFInSsHqXMJHldLoVGjRqmvn3/+eerVq0d6ejqPPPKIppPcPloph06ns3i/cuVK+vbtW+h8SiEhIRbDY+Pj4zXFcCdPT09N+ypJN1FSkkh38yCzmOcqK7TWuSKROlcOUueiqVs3/5aPIi+IYGdnR2BgICaTifDwcLp27VroPgaDweLht4SEBNzd3S3KnDt3jjlz5gBw8+ZNjh07hp2dHQ8//HBRQyxZsi6zEKISKTQp/P7771y4cAEvLy8eeughsrKy2LFjB5s3b8bFxUVTUvDx8SE6OprY2Fg8PDzYv38/w4cPtyizYMECi9dt2rSxfULgn+ktQPoUhBCVQoFJYdOmTXz99dfUq1ePv//+m8cee4xTp05RpUoVBg8eTOvWrTWdxN7enoEDBzJlyhTMZjNBQUHUq1ePH374AYDQ0NC7r4m1xESDnR14VoKH9IQQlV6BSSE8PJz333+fRo0acfbsWSZOnMhLL73Ek08+WeQTtW7dOlcSyS8ZFOX5B6uLNYKhFrrKtvSoEKJSKrBXNykpiUaNGgHZ8x9VqVKFbt26lUpgZYUSawSZ3kIIUUkU+pyCoiiYzWbMZjNVqlQBUN+bzWarB2hLiqJAjFGW4BRCVBoFtomkp6fTp08fi213vq/Qcx/duAYZ6TI7qhCi0igwKcyfP7+04iibZDiqEKKSKTApVKaV1fKizo4qzUdCiEpC09xHlVaMEfR6MFTu5CiEqDwkKRRAiTWCpxc6O3tbhyKEEKVCkkJBYqOl6UgIUakUKSnEx8dz9uxZa8VSpihmM8RGy3BUIUSloukx3fj4eObMmcOFCxcAWLNmDb/88gvHjx/n9ddft2Z8tnMtAW5lyhKcQohKRdOdwueff06rVq1YtWoV+n+me3jwwQf57bffrBqcTanDUeUZBSFE5aEpKURFRdG9e3eLtQ6cnJxITU21WmC2JsNRhRCVkaakUL16da5evWqx7fLlyxV7paNYIzg4QA1D4WWFEKKC0NSn8NRTT/Hxxx/TvXt3zGYzERERbNy4ke7du1s5PNtRYoxQsw66QlaCE0KIikRTUujcuTMuLi7s3LkTg8HA3r176d27d5lYBMdqYo1Qt76toxBCiFKlKSmYzWYefvjhip0EbqNkZUFcDLqW7WwdihBClCpNbSOvvfYay5Yt48yZM9aOp2xIjIMsk3QyCyEqHU13ChMmTGDfvn3MmTMHOzs7OnToQMeOHalfv4I2r/yzLrPMjiqEqGw0JYV7772Xe++9lxdffJHTp08TERHBBx98QI0aNfj000+tHWOpU2Kis1/InYIQopIp8tCaunXr4u3tjcFgIC4uzhox2V6sEapWA7cato5ECCFKlaY7hZSUFA4ePEhERASRkZE8+OCDPPPMM/j7+1s7PpvIXpe5LjqdztahCCFEqdKUFAYPHsx9991Hx44dGT16NE5OTtaOy7ZijOgaNrF1FEIIUeo0JYV58+bh7u5u7VjKBMV0C+Jj4eFAW4cihBClLt+kcPr0aXx9fQG4cuUKV65cybNcixYtrBOZrcTHgGKW2VGFEJVSvklh+fLlzJw5E4BFixblWUan0zF//nzrRGYr/4w8knUUhBCVUb5JISchACxYsKBUgikLlH+eUZDhqEKIykjTkNQZM2bkub0iPqNArBGcXNC5uNk6EiGEKHWaksKpU6eKtL08U2RdZiFEJVbg6KOvvvoKAJPJpL7OERMTQ82aNa0Xma3EGNE1bW7rKIQQwiYKTAoJCQlA9iypOa9zeHp60qtXL+tFZgNKZkb2ZHgy8kgIUUkVmBSGDBkCQNOmTQkJCbmrEx0/fpywsDDMZjPBwcG5Fuj5+eef2bx5MwCOjo68+uqrNGzY8K7OWWRx/6wuJ+syCyEqqXyTQmxsLLVq1QLggQceICYmJs9ytWvXLvQkZrOZ5cuXM2HCBAwGA+PGjcPf3x9vb2+1TK1atZg8eTIuLi4cO3aMzz//nKlTpxa1Pnfnn3WZZTiqEKKyyjcpjB49mtWrVwMwfPjwfA9wZ19DXqKiovDy8lITSEBAAIcPH7ZICvfdd5/6ukmTJrmaq0qDEpudFKT5SAhRWeWbFHISAmi78BckMTERg8GgvjcYDERGRuZbfteuXbRq1SrPz8LDwwkPDwdg+vTpeHp6FismvV6fa98bNxLJrO5OzfoNinXMsi6vOld0UufKQepcgsctzk4xMTHY2dlpHn2kKEqubfnNQHry5El2797NBx98kOfnISEhFv0b8fHxmmK4k6enZ659sy6dh5pexT5mWZdXnSs6qXPlIHUumrp1828N0fScwuzZs/nzzz8B2L17N6NGjWLUqFHs2rVLUwAGg8GiOSghISHPCfYuXrzIkiVLGDNmDK6urpqOXaJiomW1NSFEpaYpKZw8eRIfHx8AvvvuOyZOnMjUqVPZtGmTppP4+PgQHR1NbGwsJpOJ/fv351qLIT4+nk8//ZShQ4cWmMWsRUlPhRuJ8uCaEKJS09R8ZDKZ0Ov1JCYmkpycTLNmzQC4ceOGppPY29szcOBApkyZgtlsJigoiHr16vHDDz8AEBoayoYNG0hOTmbZsmXqPtOnTy9OnYonVibCE0IITUmhYcOGbNy4kbi4OFq3bg1kdx5Xq1ZN84lat26t7psjNDRUff3666/z+uuvaz5eSVPXZZbmIyFEJaap+ej111/n0qVLZGZm0rt3bwDOnj1Lx44drRpcqVKHo8qDa0KIykvTnYKXlxcjRoyw2NauXTvatWtnlaBsIuYK1DCgq+po60iEEMJmNA9J3b17N3v37iUxMREPDw8CAwMJCgqyZmylSmZHFUIIjUnhm2++Yc+ePTz11FPq2Nhvv/2Wa9eu0bNnT2vHWDpijOhaVaA7HyGEKAZNSWHnzp1MnjzZ4mE1Pz8/Jk2aVCGSgpKSDMk3ofY9tg5FCCFsSlNHc0ZGBm5uliuRubq6kpmZaZWgSl1szkR40skshKjcNCWFli1bMnfuXIxGI5mZmVy5coX58+fj5+dn7fhKhRIjE+EJIQRobD4aOHAgK1asYMyYMeqDbO3bt2fAgAHWjq90xBpBp4OaXraORAghbKrQpJCSkkJMTAyvvPIKQ4YMISkpCVdXV+zsNN1klA8x0eBRE10VB1tHIoQQNlVgUjh69CizZs0iMzMTR0dHxowZQ4sWLUortlKjxFyR4ahCCEEhfQpfffUVffv2ZfXq1fTu3Zu1a9eWVlylRlEUiJXZUYUQAgpJCjExMXTt2pWqVavy2GOPcfXq1dKKq/Qk34S0FJCRR0IIUXBSuH1xHHt7e7KysqweUKlT12WWZxSEEKLAPoWMjAwmTZqkvk9PT7d4D/D+++9bJ7JSIsNRhRDiXwUmhTunsq5Icx2pYo1gZweGWraORAghbK7ApPDoo4+WUhg2FGMEz9ro9MVarloIISqUCvSwQfEosUaZ80gIIf5RqZPCv8NRZeSREEJAJU8K3EiEjHR5cE0IIf5RuZPCP+syy4NrQgiRTVPv6q1bt9iwYQP79u0jKSmJVatWceLECaKjo+natau1Y7QaJWddZrlTEEIIQGNSWLVqFYmJiQwfPpypU6cCUK9ePVatWlWukwIxV0CvBw9PW0ciCqAoCunp6ZjNZnQ6XZH2jYmJISMjw0qRlU1S58qhsDorioKdnR2Ojo5F+rvRlBQOHTrE3LlzLQ7u4eFBYmKi5hOVRUpMNNSsg87O3tahiAKkp6dTpUoV9MUYNqzX67G3r1w/X6lz5aClziaTifT0dKpVq6b5uJr6FPR6PWaz2WLbzZs3cXV11XyiMinWCDLyqMwzm83FSghCVHZ5XbsLoykptGvXjvnz5xMbGwvAtWvXWL58OQEBAUWPsoxQzObs4ajyjEKZV9QmIyHEv4r696MpKbzwwgvUqlWLt956i9TUVIYPH467uzvPPfdcsYIsC8zxMWC6JbOjCiHEbTQ3H/Xv3581a9awdOlSVq9eTf/+/cv1Lb0p+jIgw1GFNk2aNFFf79y5kw4dOnDlyhVmzpyJj48P8fHxeZbNz0svvcSNGzcKLPPss89y4sSJXNu/+uor3n333SJEr93ixYsJDAykc+fOhISEsH79+gJjKY4TJ04wceJEIHvSzd69e9OlSxc2b97M6NGjOXv27F0df+nSpWrckN2u3qJFC6ZNm2ZRrm3bthb9ovv37+fll19W3+/atYvHH3+cRx55hMDAQD744IO7igvgt99+Izg4mA4dOjBx4kSLmahzZGZmMnLkSIKDgwkJCWH//v3qZ88++yydOnWiS5cudO7cWf29CwsL46uvvrrr+EBjR3NMTIzF+7S0NPV17dq1SySQ0pYV/Xf2C0kKogh+/vlnJk6cyP/+9z/uuSe76dHDw4MlS5YU6UK9Zs0aa4VYIEVR1FEpd1q9ejV79+5l69atuLq6cvPmTbZv317iMfj5+eHn5wfAyZMnMZlM/PjjjwA888wzRTpWVlaWRWeryWTiq6++soh7z549+Pj4sGXLFsaOHaupOeXMmTNMmDCB1atX07hxY0wmE//973+LFFtexo0bx8cff0ybNm146aWX2L17N507d7Yo87///Q/I/vIRHx/Piy++yPfff6/+zObPn4+fnx96vR6TyQRAnz59eOaZZ+jdu/ddx6gpKQwfPjzfz0oqO5W2LOPf4FAVanjYOhRRBOa1S1H+/kt7eZ0uz29jt9PVuxe7Pq8VeqyDBw/y9ttvs2bNGho2bKhu79OnD+vWrWPIkCG4u7tb7PP111+zYsUKMjMzadWqFdOmTcPe3p62bduybds2PDw8mDVrFhs3bqRu3bp4eHjw4IMPqjMUf/fdd4wfP54bN24wc+ZM2rZtC4DRaKRv375cunSJHj16MGrUKACWLFmi/k0+//zzvPbaa/z999+8+OKLBAQEcOTIEVasWMGnn37Kb7/9hk6no3fv3gwaNIh58+axfv16dQCJm5sbvXr1yvX/MHbsWE6cOEF6ejrdunVj9OjRAEydOpUffvgBvV5PYGAg7733Hlu2bGHWrFnY2dnh5ubGN998w/79+1m8eDGfffYZw4cPJyEhgS5durB06VJGjx7NxIkT8fPzY8+ePXz66adkZmbSoEEDZs2ahbOzM23btqVPnz7s2bOHAQMGWCSSffv20aJFC4tWjE2bNvHKK6+wevVqjhw5gr+/f6E/64ULFzJ8+HAaN24M/NtacjdiYmJISkpSz//ss8+yffv2XEnh7NmzdOzYEQBPT0/c3Nw4ceIErVq1yvfY1apVo169ehw7dqzAclpoSgp3XvivX7/O+vXruf/+++/q5LZkMv4Nteqgy+MbkxB3yszMZODAgaxfv169UORwdnamT58+LF++XL1AAkRGRvLtt9+yadMmqlSpwrhx4/jmm28s+uJOnDjB999/z44dO8jKyuKxxx7jwQcfVD83mUxs3bqVnTt38tlnn6l/i8ePH2fnzp1Uq1aNbt26ERwcjE6nY926dWzbtg2TycSTTz5J+/btqV69OufOneOzzz5j2rRp/Pbbb1y9epVdu3YBcOPGDZKTk0lJSbFIdvl55513cHd3Jysri969e3P69Gnq1KnDtm3b2Lt3LzqdTm0amz17Nl988QV16tTJ1Vzm6enJJ598wuLFi1m9erXFZ4mJicyZM4evvvoKJycnFixYwOeff87IkSMBqFq1Kps2bcoV2+HDhy3+/9LS0ti3bx8zZszg5s2bbN68WVNS+PPPPxk8eHCh5fbt28fkyZNzba9WrRrffvutxbarV69Sp86/fZh16tTJczVLX19fduzYwTPPPIPRaOT333/HaDSqF/tRo0ZhZ2fHU089xbBhw9Q7nwcffJCDBw+WTlK4U40aNejfvz8jRoxQM1p5kxV9Gby8bR2GKCIt3+hvd/st9t3Q6/W0adOGtWvX5tm2PHDgQEJDQy0uJBEREfz+++888cQTQPbzFp6elg9KHjp0iMcee0wdR96lSxeLz3P2ffDBB7l8+bK6vVOnTnh4ZN/lPv744xw6dAidTkfXrl1xdnbGZDLx+OOPc/DgQUJDQ/H29qZNmzYA1K9fn0uXLjFhwgSCg4N55JFHSElJ0TxKZcuWLXzxxRdkZWURExNDZGQkTZs2pWrVqowePVptCwfw9/dn5MiRPPXUUzz++OOajg9w5MgRzp49q94F3Lp1S40f4Omnn85zv9jYWIs+nfDwcAICAqhWrRpPPPEEs2fPZvLkydjb2+dZ36KO1OnQoYPa9FWYvO5Y8zpfnz59iIyM5PHHH8fb2xt/f3/1zmfevHnUqVOH5ORkBg0aRJ06ddQvGZ6enkRFRRUp/rwUu6fYaDQW6QnC48ePExYWhtlsJjg4mO7du1t8rigKYWFhHDt2jKpVqzJkyBAaNWpU3PAKpGRlYY65gs7vIascX1Q8dnZ2LFmyhN69ezN37txcTarVq1ene/furFq1St2mKArPPfcc48aNy/e4hTVtOTg4ANnL4d6e3O68mOgKaSZzcnJSX9eoUYMff/yRn376iZUrV7JlyxY+++wzqlWrxsWLF2nQoEG+x7l06RJLlixh69at1KhRgzfffJP09HT0ej1bt24lIiKCzZs3ExYWxvr16/n44485evQoO3fuJDQ0lB9++KHA+uZQFIXAwEAWLlxYaH1u5+joSHp6uvp+8+bNHD58WG12u3btGvv27SMwMBB3d3euX7+uJtfbXzdt2pTff/+d5s2bFxhnUe4U6tSpQ3R0tPo+Ojo6zz5ZvV5vsaLl008/zb333qseA8DFxYWePXty7NgxNSlkZGTg6OhYYLxaaGo7ee+995g0aZL6b+zYsYwfP54nn3xS00nMZjPLly9n/PjxzJo1i3379ll86wE4duwYV69eZe7cuQwaNIhly5YVvTZaJcRCVpasoyCKpFq1aqxatYqNGzfy5Zdf5vp88ODB/Pe//1XXMu/YsSPfffedOkLk2rVruX7vH374YX788UfS09NJSUlh586dmmL5+eefuXbtGmlpaezYsYOHHnqIdu3asWPHDlJTU0lNTWX79u3qxfB2iYmJmM1munXrxpgxY/j9998BGDp0KO+++y5JSUkAJCUl5epcTUpKolq1ari5uREXF8fu3bsBSElJISkpieDgYN5//31Onz4NwIULF2jdujVjxozBw8MDo9GoqX5t2rTh8OHD/PVXdv9RWloa586dK3S/xo0bc+HCBTXWQ4cOcejQIQ4ePMjBgweZOnUqmzdvBqB9+/Z8/fXXQHaH9TfffKM+e/Wf//yHefPmqec0m80sWbIk1/ly7hTu/HdnQoDsQTkuLi4cOXIERVHYsGEDjz32WK5yaWlppKamArB37170ej1NmzbFZDKpo6Vu3brFjz/+yH333afud/78eZo1a1bo/1FhNN0p3NkR4ujoSIMGDSzaxwoSFRWFl5eXmhUDAgI4fPgw3t7/Nt/8+uuvBAYGotPpaNq0KSkpKVy7di1Xx12J+GddZhmOKorK3d2d//73v/zf//2f+q0yh4eHB127dmXp0qVA9rfNt99+m+effx5FUdDr9UyZMsXi975ly5aEhobSpUsXvL298fPz0zRTwEMPPcTw4cO5cOECPXr0UEfzPPfcc+p8ZM8//zwtWrTg77//ttg3OjqaUaNGqU+65tzJ9OvXj9TUVJ544gl1WpE729WbN29OixYtCAoKon79+jz0UPbddnJyMgMHDiQjIwNFUdS13D/66CP++usvFEWhY8eONG/enAMHDhRaP4PBwKxZs3jjjTfIzMwE4O2338bHx6fA/Tp37qzexX3//fd06NCBqlWrqp+Hhoby0UcfkZGRwZtvvsm4cePUpq5HH32U//u//wOy2/UnT57MG2+8QVpaGjqdjuDg4ELjLsy0adMYOXIk6enpBAUFqdfWH374gRMnTjBmzBji4+N54YUXsLOzw8vLi7lz5wLZ/VovvPACJpOJrKwsAgMD6du3r3rsw4cPqwMO7oZOKeT+1Ww2s3DhQgYPHkyVKlWKdZJffvmF48ePqyMq9u7dS2RkJK+88opaZvr06XTv3l3NdB988AF9+/bN9UsQHh5OeHi4uk/OL0xRZJ4+Qdq3X+L6n3ewq26FpFNGlVT7emmLiYmx+MOuaFJSUnB2diY1NZXu3bvz6aefWnSWiqLp378/7733ntWan8ui33//ncWLF7NgwYJcn2VkZORqpspplsxLoXcKdnZ26tC14tLSwaK1EyYkJETN7IDFQ0Oa1boHz7HTs/ctzv7llKenZ/H+v2wsIyOj2JOdlYdEOGrUKM6ePUtGRgbPPfccvr6+dxVzeahzSbu9zmPHjsVoNFK/fn0bR2Vdt9c5Li6O0aNH5/lzz8jIyPV3X7du/q0kmpqPunXrxrp16+jVq1exnmI2GAwkJCSo7xMSEnI1CxkMBovA8yojREWU17c7UXyNGzfONWy4ogsMDCyxYxV4hY+IiKBjx45s376d69evs3XrVtzc3CzKLFq0qNCT+Pj4EB0dTWxsLB4eHuzfvz/X6A1/f3+2b99Ohw4diIyMxMnJSZKCAAofoSOEyF9R/34KTApLly6lY8eODBs27K6Csre3Z+DAgUyZMgWz2UxQUBD16tVTh6eFhobSqlUrjh49yvDhw3FwcGDIkCF3dU5RcdjZ2WEymcr1XFtC2ILJZMpzSpOCFNjR/PLLL+d60rCs0TrE7U7ltX39bpTXOt/NymtVq1atdCtySZ0rh8LqXNDKa8XuUzCbzZw8ebLAwFq0aFHg50LcLZ1OV6SVo25XXhPh3ZA6Vw7WqnOBSeHWrVssXrw43zYpnU7H/PnzSzwoIYQQtlFgUnB0dJSLvhBCVCIyRagQQghVgXcK5WEoYEEdJtbct7ySOlcOUufKwRp1LvBOoayPPLobY8eOtXUIpU7qXDlInSsHa9VZmo+EEEKoJCkIIYRQVdqkcPukepWF1LlykDpXDtaqc6FTZwshhKg8Ku2dghBCiNwkKQghhFBV+Gknjx8/TlhYGGazmeDgYLp3727xuaIohIWFcezYMapWrcqQIUPK/YpNhdX5559/VtepdXR05NVXX6Vhw4alH2gJKqzOOaKionj33XcZOXIk7dq1K90gS5iWOp86dYqVK1eSlZWFq6urxYLw5VFhdU5NTWXu3LkkJCSQlZXFU089RVBQkG2CLQELFy7k6NGjVK9enZkzZ+b63CrXL6UCy8rKUoYOHapcvXpVuXXrljJ69Gjl77//tihz5MgRZcqUKYrZbFb+/PNPZdy4cTaKtmRoqfOZM2eUpKQkRVEU5ejRo5WizjnlJk+erEydOlU5cOCADSItOVrqnJycrLz55ptKXFycoiiKcv36dVuEWmK01Pnrr79W1qxZoyiKoty4cUPp37+/cuvWLVuEWyJOnTqlnDt3Thk1alSen1vj+lWhm4+ioqLw8vKidu3a6PV6AgICOHz4sEWZX3/9lcDAQHQ6HU2bNiUlJYVr167ZKOK7p6XO9913Hy4uLgA0adLEYlW88khLnQG2bdtG27Ztcy0UVR5pqXNERARt27bF09MTgOrVq9si1BKjpc46nY709HR1unUXF5cirydQlvj6+qp/q3mxxvWr/P5vaZCYmIjBYFDfGwwGEhMTc5XJ+aPJr0x5oqXOt9u1axetWrUqjdCsRuvP+dChQ4SGhpZ2eFahpc7R0dEkJyczefJk3nnnHfbs2VPaYZYoLXXu2rUrV65cYfDgwbz11lsMGDCgXCeFwljj+lWh+xSUPEbb3rnYhJYy5UlR6nPy5El2797NBx98YO2wrEpLnVeuXEnfvn0rzAVCS52zsrL466+/mDhxIpmZmUyYMIEmTZqU2zmCtNT5xIkTNGjQgPfee4+YmBg+/PBDmjVrhpOTU2mFWaqscf2q0EnBYDBYNI0kJCTkWvfZYDBYLFSRV5nyREudAS5evMiSJUsYN24crq6upRliidNS53PnzjFnzhwAbt68ybFjx7Czs+Phhx8u1VhLitbfbVdXVxwdHXF0dOT+++/n4sWL5TYpaKnz7t276d69OzqdDi8vL2rVqoXRaKRx48alHW6psMb1q2J8bcqHj48P0dHRxMbGYjKZ2L9/P/7+/hZl/P392bt3L4qicPbsWZycnMp1UtBS5/j4eD799FOGDh1abi8Qt9NS5wULFqj/2rVrx6uvvlpuEwJo/90+c+YMWVlZZGRkEBUVxT333GOjiO+eljp7enry+++/A3D9+nWMRiO1atWyRbilwhrXrwr/RPPRo0dZtWoVZrOZoKAgevbsyQ8//ABAaGgoiqKwfPlyTpw4gYODA0OGDMHHx8fGUd+dwuq8ePFiDh48qLZF2tvbM336dFuGfNcKq/PtFixYQJs2bcr9kFQtdf7222/ZvXs3dnZ2dO7cmW7dutky5LtWWJ0TExNZuHCh2tn6zDPPEBgYaMuQ78rs2bM5ffo0SUlJVK9enV69emEymQDrXb8qfFIQQgihXYVuPhJCCFE0khSEEEKoJCkIIYRQSVIQQgihkqQghBBCJUmhAps8eTI7d+60dRgF+vnnn/noo4/y/fyPP/5gxIgRpRhR6Zk9ezaHDh2y2vFfeuklYmJi8v181KhRnDp1qkTPGRsbS69evcjKyiq07KlTp3j99deLdZ672fdOv/76K7Nnzy6RY1UEFfqJ5orkjTfe4Pr16xbTNMyZMwcPD49SjWPy5MlERkZiZ2eHg4MD999/P6+88kqxH5jp1KkTnTp1Ut/36tWLuXPn4uXlBcD999+vPolcktatW8fGjRvR6/XY29vj7e3Nyy+/TNOmTTXtf2ecRXXx4kUuXryoJryffvqJRYsW4eDggJ2dHbVq1aJPnz60adOmWMcHWLNmjfp6wYIFGAwG+vTpo2777LPPin3s8mbt2rUcPnyYK1eu0LNnT3r16qV+5u/vz5dffsnFixdp0KCBDaMsG+ROoRx55513WLNmjfqvtBNCjoEDB7JmzRrmzJlDSkoKq1atskkcd6t9+/asWbOG5cuX07x581K9SP7444906tTJYp6apk2bsmbNGsLCwujcuTOzZs0iOTm51GKqyLy8vHjxxRdp3bp1np936NCB8PDwUo6qbJI7hXIsOTmZ+fPnExkZidls5r777uO1116zmEkyx9WrV1m0aBEXLlxAr9fTokULRo4cCcCVK1dYsWIF58+fx83Njd69exMQEFDo+V1cXGjbti0//vgjAH/++ScrV67EaDRSt25d+vfvz3333QdkfxPesGEDN2/exNXVlT59+tCpUyd++ukndu7cyYcffsikSZMAGDNmDAD/+c9/qF69OvPmzWPx4sVs2rSJc+fO8dZbb6kxhIWFoSgKAwcOJDU1lVWrVnHs2DF0Oh1BQUH06tWr0Enw7O3t6dSpExs3buTmzZu4ubkRFRVFWFgYV65cwcHBgbZt29KvXz/0en2ecQYEBHDkyBHWrl1LXFwc3t7evPbaa/l+8zx+/DhDhw7N8zM7OzuCgoIICwsjJiYGOzs7VqxYoS6kEhwcTI8ePbCzsyvw55pzN3Py5EkiIiIA2Lp1K82bN2fs2LG88cYbDB48GG9vb4YNG8aSJUvUaZr/+usvPvroI5YsWYJer2fXrl1s2bKF69ev07hxYwYNGkTNmjUL+Q3Jnovo22+/JSEhATc3N5555hm6dOliUeabb75h69atODo6qr8XALdu3eLLL7/kwIEDmEwmHnroIfr374+Dg0Oh573To48+CmQ3V+bF19eXefPm8corrxT52BWNJIVyTFEUHn30UUaOHInZbGbRokUsX76ct99+O1fZtWvX4ufnx6RJkzCZTJw/fx6A9PR0PvroI3r16sX48eO5ePEiU6ZMoV69etSrV6/A89+8eZODBw/SsGFDkpOTmT59OgMGDKBDhw4cOHCA6dOnM3fuXKpUqUJYWBjTpk2jbt26XLt2Lc9vwO+//z69evXik08+UZtlbm/z7tChAxs2bCA1NRUnJyfMZjMHDhxg9OjRAMyfP58aNWowd+5cMjIymD59OgaDIddF6E4mk4k9e/bg6uqKs7MzkH1h7tevHz4+PiQkJDBt2jR27NhBt27d8ozz/PnzLFq0iHfeeQcfHx/27t3LjBkzmD17NlWqVLE4X3p6OrGxsfnOO5WVlcWuXbtwdHSkTp06rFixgtTUVObPn09SUhJTpkzB3d2dzp075/tzvV1ISAh//vlnruajHB4eHjRt2pRffvmFkJAQ4N+1GPR6PYcOHWLjxo2888471KlTh02bNjFnzpwC+4JyVK9enXfeeYfatWvzxx9/MHXqVHx8fNTVwa5fv05SUhKLFy8mMjKSadOm4ePjQ926dfniiy+IiYnhk08+wd7enjlz5rBhwwZeeOGFXOdZtmwZAK+++mqhMeXF29ubuLg49XerMpPmo3Lkk08+oX///vTv358ZM2bg6upKu3btqFq1KtWqVaNnz5788ccfee6r1+uJi4vj2rVrODg40KxZMyB7LpmaNWsSFBSEvb09jRo1om3btvzyyy/5xhEWFkb//v0ZM2YM7u7u9OvXj6NHj+Ll5UVgYCD29vZ07NiRunXrcuTIESB7Ot9Lly6RmZmJu7t7oQknLzVr1uTee+9VF1Y5efIkVatWpWnTply/fp3jx4/Tv39/HB0dqV69Ot26dWP//v35Hu/AgQP079+fvn37snPnTkaNGoW9vT0AjRo1omnTptjb21OrVi1CQkI4ffp0vsfauXMnISEhNGnSBDs7Ox599FH0ej2RkZG5yqampgLZS6HeLjIykv79+zNo0CD27dvH6NGjcXR0ZP/+/bzwwgtUq1aNWrVq8eSTT7J3714g/59rUXXs2JF9+/YB2V829u/fT8eOHQEIDw+nR48eeHt7Y29vT48ePbhw4QJxcXGFHrd169Z4eXmh0+nw9fXlwQcf5MyZMxZlevfuTZUqVfD19aVVq1bs378fRVHYuXMn/fr1w8XFRf39zonxTq+++mqxEwL8+7PI+dlUZnKnUI6MGTOGBx98UH2fkZHBqlWrOH78OCkpKQCkpaVhNptzNZm8+OKLrF27lvHjx+Ps7MyTTz5J586diYuLUy9GObKysgqcRGzAgAEEBwdbbEtMTMzVnFCzZk0SExNxdHTkzTffZMuWLSxevJj77ruPl19+uVgzduZcvB555BEiIiLo0KEDkD3za1ZWFoMGDVLLKoqSZ1Najvbt2zN8+HBu3rzJzJkzOX/+PM2bNwfAaDSyevVqzp07R2ZmJllZWQWufRsfH8+ePXvYvn27us1kMuW54EnON9H09HSLppAmTZrw4YcfWpS9fv06JpPJYiGVnP9XyP/nWlTt2rVjxYoVJCYmcvXqVSC7kx8gLi6OsLAwVq9erZZXFCXPn/mdjh07xoYNGzAajSiKQkZGBvXr11c/d3Z2tkiONWvW5Nq1a9y8eZOMjAzGjh1rcU6z2VzkummRnp4OUOnvEkCSQrm2ZcsWjEYjU6dOpUaNGly4cIG33347z4U3atSooQ7hO3PmDB9++CG+vr4YDAZ8fX2ZOHHiXcXi4eHBwYMHLbbFx8fTsmVLAFq2bEnLli3JzMxk7dq1LFmypFiL+7Rv357Vq1eTkJDAoUOH1CYMg8GAXq9n+fLl6rd9rdzc3Bg0aBDjxo2jY8eOuLu7s2zZMho2bMiIESOoVq0aW7duLfDuyWAw0LNnT3r27Fno+RwdHalduzZGo7HQpUHd3Nywt7cnPj4eb29vIPv/NWeQQX4/1ztHRRW28IqzszN+fn4cOHCAK1eu0KFDB3UfT09PevbsaTFKTItbt24xc+ZMhg4dir+/P3q9nhkzZliUSUlJIT09XU0M8fHx1KtXD1dXVxwcHPjss89KZUDF5cuXqVmzpiQFpPmoXMv5punk5ERycjLr16/Pt+yBAwfUBUpubzdv06YN0dHR7N27F5PJhMlkIioqisuXLxcpllatWhEdHU1ERARZWVns37+fy5cv07p1a65fv86vv/5Keno6er0eR0fHfDt/q1evXuDYejc3N5o3b87ChQupVauWeqF0d3fHz8+P1atXk5qaitls5urVqwU2+dzunnvuwc/Pj82bNwPZd1xOTk44Ojpy5coVdXrm/OIMDg7mxx9/JDIyUl0f+OjRo6SlpeX7/6UlNjs7O9q3b8+XX35JWloacXFxfPfdd+oFOr+f650K+3+F7LuwvXv3cvDgQbXpCKBLly5s2rSJv//+G8huYjlw4EChsZtMJm7duqUmtmPHjvHbb7/lKrdu3TpMJhN//PEHR48epX379tjZ2REcHMzKlSu5ceMGkH03evz48ULPm18smZmZ6t1GZmamxV3H6dOny/2ytCVF7hTKsSeeeIK5c+fyyiuv4OHhwZNPPpnngvWQvfLYypUrSU1NpUaNGgwYMEBdfGTChAmsWrWKVatWoSgKDRo0oF+/fkWKxdXVlbFjxxIWFsbSpUvx8vJi7NixuLm5ce3aNbZs2cK8efPQ6XQ0bNgw3/bf5557jgULFpCZmcmgQYPyXGy+Y8eOzJ8/nxdffNFi+9ChQ/niiy8YNWoUaWlp1K5dm2eeeUZzHZ5++mk++OADevTowUsvvcTnn3/O5s2buffeewkICODkyZP5xhkQEMDgwYNZsWIF0dHRavt+ThPMnUJCQpg9ezY9evQo9Fv8wIEDWbFiBUOHDsXBwYHg4GCCgoKAgn+ut+vcuTOfffYZ/fv3x9fXN8/BCP7+/ixevBhPT08aNmyobn/44YdJT09n9uzZxMfH4+TkxAMPPED79u0LjLtatWoMGDCAWbNmcevWLdq0aZNrUZwaNWrg4uLC4MGDcXBw4LXXXlObFfv27cuGDRt49913SUpKwsPDgy5duqh3n7f7/PPPASyaD2+3ZMkSizWqv/nmG4YMGaKOStq3bx/Dhg0rsD6VhaynIISNzJkzh/bt25frFeAqgl9//ZW9e/cyatQoW4dSJkhSEEIIoZI+BSGEECpJCkIIIVSSFIQQQqgkKQghhFBJUhBCCKGSpCCEEEIlSUEIIYTq/wGMHQ5sBmpE3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "p_svc = SVC(kernel = 'poly')\n",
    "metrics.plot_roc_curve(p_svc.fit(X_train, Y_train), X_test, Y_test)\n",
    "metrics.plot_roc_curve(randomforest.fit(X_train, Y_train), X_test, Y_test)\n",
    "metrics.plot_roc_curve(knn.fit(X_train, Y_train), X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Breast Cancer Detection Using Various Architectures.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
